{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_prefix = 'automated-job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "timestamp_prefix = 'automated-job'\n",
    "\n",
    "prefix = 'sagemaker/spark-preprocess-demo/' + timestamp_prefix\n",
    "input_prefix = prefix + '/input/raw/abalone'\n",
    "input_preprocessed_prefix = prefix + '/input/preprocessed/abalone'\n",
    "model_prefix = prefix + '/model'\n",
    "#Jay Change\n",
    "mleap_model_prefix = prefix + '/mleap-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-19 14:52:26--  https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/abalone/abalone.csv\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.209.216\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.209.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 191873 (187K) [binary/octet-stream]\n",
      "Saving to: ‘abalone.csv.2’\n",
      "\n",
      "abalone.csv.2       100%[===================>] 187.38K   866KB/s    in 0.2s    \n",
      "\n",
      "2020-08-19 14:52:26 (866 KB/s) - ‘abalone.csv.2’ saved [191873/191873]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/automated-job/input/raw/abalone/abalone.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the dataset from the SageMaker bucket\n",
    "!wget https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/abalone/abalone.csv\n",
    "\n",
    "# Uploading the training data to S3\n",
    "sagemaker_session.upload_data(path='abalone.csv', bucket=bucket, key_prefix=input_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sagemaker-ml-workflow-with-apache-airflow/container\n",
      "Sending build context to Docker daemon  44.03kB\n",
      "Step 1/32 : FROM openjdk:8-jre-slim\n",
      "8-jre-slim: Pulling from library/openjdk\n",
      "\n",
      "\u001b[1B52930446: Pulling fs layer \n",
      "\u001b[1B9b8e633f: Pulling fs layer \n",
      "\u001b[1B86d6fc62: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:c8740afc9ec89f879bdb3d02cb885a8c3fff565f2f850020127194765922b631[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for openjdk:8-jre-slim\n",
      " ---> d2f9f3c77c25\n",
      "Step 2/32 : RUN apt-get update\n",
      " ---> Running in 4a5a2ac05cba\n",
      "Get:1 http://deb.debian.org/debian buster InRelease [122 kB]\n",
      "Get:2 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [220 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7906 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [7868 B]\n",
      "Fetched 8374 kB in 1s (5662 kB/s)\n",
      "Reading package lists...\n",
      "Removing intermediate container 4a5a2ac05cba\n",
      " ---> 5b75000c83fb\n",
      "Step 3/32 : RUN apt-get install -y curl unzip python3 python3-setuptools python3-pip python-dev python3-dev python-psutil\n",
      " ---> Running in a9a5c5b6668b\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-8 dbus dh-python dirmngr dpkg-dev fakeroot file g++ g++-8 gcc gcc-8\n",
      "  gir1.2-glib-2.0 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm krb5-locales libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libapparmor1 libasan5\n",
      "  libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libcurl4\n",
      "  libdbus-1-3 libdpkg-perl libexpat1 libexpat1-dev libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-8-dev libgdbm-compat4 libgdbm6\n",
      "  libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libgomp1 libgssapi-krb5-2\n",
      "  libicu63 libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libksba8 libldap-2.4-2 libldap-common liblocale-gettext-perl\n",
      "  liblsan0 libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2\n",
      "  libnghttp2-14 libnpth0 libperl5.28 libpsl5 libpython-dev libpython-stdlib\n",
      "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
      "  libpython2.7-minimal libpython2.7-stdlib libpython3-dev libpython3-stdlib\n",
      "  libpython3.7 libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib\n",
      "  libquadmath0 libreadline7 librtmp1 libsasl2-2 libsasl2-modules\n",
      "  libsasl2-modules-db libsqlite3-0 libssh2-1 libstdc++-8-dev libtsan0\n",
      "  libubsan1 libxml2 linux-libc-dev make manpages manpages-dev mime-support\n",
      "  netbase patch perl perl-modules-5.28 pinentry-curses publicsuffix python\n",
      "  python-minimal python-pip-whl python2 python2-dev python2-minimal python2.7\n",
      "  python2.7-dev python2.7-minimal python3-asn1crypto python3-cffi-backend\n",
      "  python3-crypto python3-cryptography python3-dbus python3-distutils\n",
      "  python3-entrypoints python3-gi python3-keyring python3-keyrings.alt\n",
      "  python3-lib2to3 python3-minimal python3-pkg-resources python3-secretstorage\n",
      "  python3-six python3-wheel python3-xdg python3.7 python3.7-dev\n",
      "  python3.7-minimal readline-common shared-mime-info xdg-user-dirs xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-8-locales default-dbus-session-bus\n",
      "  | dbus-session-bus dbus-user-session libpam-systemd pinentry-gnome3 tor\n",
      "  debian-keyring g++-multilib g++-8-multilib gcc-8-doc libstdc++6-8-dbg\n",
      "  gcc-multilib autoconf automake libtool flex bison gdb gcc-doc gcc-8-multilib\n",
      "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan5-dbg\n",
      "  liblsan0-dbg libtsan0-dbg libubsan1-dbg libmpx2-dbg libquadmath0-dbg\n",
      "  parcimonie xloadimage scdaemon glibc-doc sensible-utils git bzr gdbm-l10n\n",
      "  krb5-doc krb5-user libsasl2-modules-gssapi-mit\n",
      "  | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp\n",
      "  libsasl2-modules-sql libstdc++-8-doc make-doc man-browser ed diffutils-doc\n",
      "  perl-doc libterm-readline-gnu-perl | libterm-readline-perl-perl\n",
      "  libb-debug-perl liblocale-codes-perl pinentry-doc python-doc python-tk\n",
      "  python-psutil-doc python2-doc python2.7-doc binfmt-support python3-doc\n",
      "  python3-tk python3-venv python-crypto-doc python-cryptography-doc\n",
      "  python3-cryptography-vectors python-dbus-doc python3-dbus-dbg gnome-keyring\n",
      "  libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-secretstorage-doc\n",
      "  python-setuptools-doc python3.7-venv python3.7-doc readline-doc zip\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-8 curl dbus dh-python dirmngr dpkg-dev fakeroot file g++ g++-8 gcc gcc-8\n",
      "  gir1.2-glib-2.0 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm krb5-locales libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libapparmor1 libasan5\n",
      "  libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libcurl4\n",
      "  libdbus-1-3 libdpkg-perl libexpat1 libexpat1-dev libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-8-dev libgdbm-compat4 libgdbm6\n",
      "  libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libgomp1 libgssapi-krb5-2\n",
      "  libicu63 libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libksba8 libldap-2.4-2 libldap-common liblocale-gettext-perl\n",
      "  liblsan0 libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2\n",
      "  libnghttp2-14 libnpth0 libperl5.28 libpsl5 libpython-dev libpython-stdlib\n",
      "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
      "  libpython2.7-minimal libpython2.7-stdlib libpython3-dev libpython3-stdlib\n",
      "  libpython3.7 libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib\n",
      "  libquadmath0 libreadline7 librtmp1 libsasl2-2 libsasl2-modules\n",
      "  libsasl2-modules-db libsqlite3-0 libssh2-1 libstdc++-8-dev libtsan0\n",
      "  libubsan1 libxml2 linux-libc-dev make manpages manpages-dev mime-support\n",
      "  netbase patch perl perl-modules-5.28 pinentry-curses publicsuffix python\n",
      "  python-dev python-minimal python-pip-whl python-psutil python2 python2-dev\n",
      "  python2-minimal python2.7 python2.7-dev python2.7-minimal python3\n",
      "  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n",
      "  python3-dbus python3-dev python3-distutils python3-entrypoints python3-gi\n",
      "  python3-keyring python3-keyrings.alt python3-lib2to3 python3-minimal\n",
      "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
      "  python3-six python3-wheel python3-xdg python3.7 python3.7-dev\n",
      "  python3.7-minimal readline-common shared-mime-info unzip xdg-user-dirs\n",
      "  xz-utils\n",
      "0 upgraded, 154 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 178 MB of archives.\n",
      "After this operation, 521 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 perl-modules-5.28 all 5.28.1-6+deb10u1 [2873 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 libgdbm6 amd64 1.18.1-4 [64.7 kB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libgdbm-compat4 amd64 1.18.1-4 [44.1 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 libperl5.28 amd64 5.28.1-6+deb10u1 [3894 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 perl amd64 5.28.1-6+deb10u1 [204 kB]\n",
      "Get:6 http://deb.debian.org/debian buster/main amd64 libpython2.7-minimal amd64 2.7.16-2+deb10u1 [395 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 python2.7-minimal amd64 2.7.16-2+deb10u1 [1369 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 python2-minimal amd64 2.7.16-1 [41.4 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 python-minimal amd64 2.7.16-1 [21.0 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 mime-support all 3.62 [37.2 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libexpat1 amd64 2.2.6-2+deb10u1 [106 kB]\n",
      "Get:12 http://deb.debian.org/debian buster/main amd64 readline-common all 7.0-5 [70.6 kB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 libreadline7 amd64 7.0-5 [151 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 libsqlite3-0 amd64 3.27.2-3 [641 kB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 libpython2.7-stdlib amd64 2.7.16-2+deb10u1 [1912 kB]\n",
      "Get:16 http://deb.debian.org/debian buster/main amd64 python2.7 amd64 2.7.16-2+deb10u1 [305 kB]\n",
      "Get:17 http://deb.debian.org/debian buster/main amd64 libpython2-stdlib amd64 2.7.16-1 [20.8 kB]\n",
      "Get:18 http://deb.debian.org/debian buster/main amd64 libpython-stdlib amd64 2.7.16-1 [20.8 kB]\n",
      "Get:19 http://deb.debian.org/debian buster/main amd64 python2 amd64 2.7.16-1 [41.6 kB]\n",
      "Get:20 http://deb.debian.org/debian buster/main amd64 python amd64 2.7.16-1 [22.8 kB]\n",
      "Get:21 http://deb.debian.org/debian buster/main amd64 liblocale-gettext-perl amd64 1.07-3+b4 [18.9 kB]\n",
      "Get:22 http://deb.debian.org/debian buster/main amd64 libpython3.7-minimal amd64 3.7.3-2+deb10u2 [589 kB]\n",
      "Get:23 http://deb.debian.org/debian buster/main amd64 python3.7-minimal amd64 3.7.3-2+deb10u2 [1731 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:24 http://deb.debian.org/debian buster/main amd64 python3-minimal amd64 3.7.3-1 [36.6 kB]\n",
      "Get:25 http://deb.debian.org/debian buster/main amd64 libmpdec2 amd64 2.4.2-2 [87.2 kB]\n",
      "Get:26 http://deb.debian.org/debian buster/main amd64 libpython3.7-stdlib amd64 3.7.3-2+deb10u2 [1732 kB]\n",
      "Get:27 http://deb.debian.org/debian buster/main amd64 python3.7 amd64 3.7.3-2+deb10u2 [330 kB]\n",
      "Get:28 http://deb.debian.org/debian buster/main amd64 libpython3-stdlib amd64 3.7.3-1 [20.0 kB]\n",
      "Get:29 http://deb.debian.org/debian buster/main amd64 python3 amd64 3.7.3-1 [61.5 kB]\n",
      "Get:30 http://deb.debian.org/debian buster/main amd64 netbase all 5.6 [19.4 kB]\n",
      "Get:31 http://deb.debian.org/debian buster/main amd64 bzip2 amd64 1.0.6-9.2~deb10u1 [48.4 kB]\n",
      "Get:32 http://deb.debian.org/debian buster/main amd64 libapparmor1 amd64 2.13.2-10 [94.7 kB]\n",
      "Get:33 http://deb.debian.org/debian buster/main amd64 libdbus-1-3 amd64 1.12.20-0+deb10u1 [215 kB]\n",
      "Get:34 http://deb.debian.org/debian buster/main amd64 dbus amd64 1.12.20-0+deb10u1 [236 kB]\n",
      "Get:35 http://deb.debian.org/debian buster/main amd64 libmagic-mgc amd64 1:5.35-4+deb10u1 [242 kB]\n",
      "Get:36 http://deb.debian.org/debian buster/main amd64 libmagic1 amd64 1:5.35-4+deb10u1 [117 kB]\n",
      "Get:37 http://deb.debian.org/debian buster/main amd64 file amd64 1:5.35-4+deb10u1 [66.4 kB]\n",
      "Get:38 http://deb.debian.org/debian buster/main amd64 krb5-locales all 1.17-3 [95.4 kB]\n",
      "Get:39 http://deb.debian.org/debian buster/main amd64 manpages all 4.16-2 [1295 kB]\n",
      "Get:40 http://deb.debian.org/debian buster/main amd64 xz-utils amd64 5.2.4-1 [183 kB]\n",
      "Get:41 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]\n",
      "Get:42 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]\n",
      "Get:43 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]\n",
      "Get:44 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]\n",
      "Get:45 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]\n",
      "Get:46 http://deb.debian.org/debian buster/main amd64 linux-libc-dev amd64 4.19.132-1 [1376 kB]\n",
      "Get:47 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]\n",
      "Get:48 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]\n",
      "Get:49 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]\n",
      "Get:50 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]\n",
      "Get:51 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]\n",
      "Get:52 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]\n",
      "Get:53 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]\n",
      "Get:54 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]\n",
      "Get:55 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]\n",
      "Get:56 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]\n",
      "Get:57 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]\n",
      "Get:58 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]\n",
      "Get:59 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]\n",
      "Get:60 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]\n",
      "Get:61 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]\n",
      "Get:62 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]\n",
      "Get:63 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]\n",
      "Get:64 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]\n",
      "Get:65 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]\n",
      "Get:66 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]\n",
      "Get:67 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]\n",
      "Get:68 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]\n",
      "Get:69 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]\n",
      "Get:70 http://deb.debian.org/debian buster/main amd64 libdpkg-perl all 1.19.7 [1414 kB]\n",
      "Get:71 http://deb.debian.org/debian buster/main amd64 patch amd64 2.7.6-3+deb10u1 [126 kB]\n",
      "Get:72 http://deb.debian.org/debian buster/main amd64 dpkg-dev all 1.19.7 [1773 kB]\n",
      "Get:73 http://deb.debian.org/debian buster/main amd64 build-essential amd64 12.6 [7576 B]\n",
      "Get:74 http://deb.debian.org/debian buster/main amd64 libkeyutils1 amd64 1.6-6 [15.0 kB]\n",
      "Get:75 http://deb.debian.org/debian buster/main amd64 libkrb5support0 amd64 1.17-3 [65.6 kB]\n",
      "Get:76 http://deb.debian.org/debian buster/main amd64 libk5crypto3 amd64 1.17-3 [121 kB]\n",
      "Get:77 http://deb.debian.org/debian buster/main amd64 libkrb5-3 amd64 1.17-3 [370 kB]\n",
      "Get:78 http://deb.debian.org/debian buster/main amd64 libgssapi-krb5-2 amd64 1.17-3 [158 kB]\n",
      "Get:79 http://deb.debian.org/debian buster/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-1+deb10u1 [69.1 kB]\n",
      "Get:80 http://deb.debian.org/debian buster/main amd64 libsasl2-2 amd64 2.1.27+dfsg-1+deb10u1 [106 kB]\n",
      "Get:81 http://deb.debian.org/debian buster/main amd64 libldap-common all 2.4.47+dfsg-3+deb10u2 [89.7 kB]\n",
      "Get:82 http://deb.debian.org/debian buster/main amd64 libldap-2.4-2 amd64 2.4.47+dfsg-3+deb10u2 [224 kB]\n",
      "Get:83 http://deb.debian.org/debian buster/main amd64 libnghttp2-14 amd64 1.36.0-2+deb10u1 [85.0 kB]\n",
      "Get:84 http://deb.debian.org/debian buster/main amd64 libpsl5 amd64 0.20.2-2 [53.7 kB]\n",
      "Get:85 http://deb.debian.org/debian buster/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2 [60.5 kB]\n",
      "Get:86 http://deb.debian.org/debian buster/main amd64 libssh2-1 amd64 1.8.0-2.1 [140 kB]\n",
      "Get:87 http://deb.debian.org/debian buster/main amd64 libcurl4 amd64 7.64.0-4+deb10u1 [331 kB]\n",
      "Get:88 http://deb.debian.org/debian buster/main amd64 curl amd64 7.64.0-4+deb10u1 [264 kB]\n",
      "Get:89 http://deb.debian.org/debian buster/main amd64 python3-lib2to3 all 3.7.3-1 [76.7 kB]\n",
      "Get:90 http://deb.debian.org/debian buster/main amd64 python3-distutils all 3.7.3-1 [142 kB]\n",
      "Get:91 http://deb.debian.org/debian buster/main amd64 dh-python all 3.20190308 [99.3 kB]\n",
      "Get:92 http://deb.debian.org/debian buster/main amd64 libassuan0 amd64 2.5.2-1 [49.4 kB]\n",
      "Get:93 http://deb.debian.org/debian buster/main amd64 gpgconf amd64 2.2.12-1+deb10u1 [510 kB]\n",
      "Get:94 http://deb.debian.org/debian buster/main amd64 libksba8 amd64 1.3.5-2 [99.7 kB]\n",
      "Get:95 http://deb.debian.org/debian buster/main amd64 libnpth0 amd64 1.6-1 [18.4 kB]\n",
      "Get:96 http://deb.debian.org/debian buster/main amd64 dirmngr amd64 2.2.12-1+deb10u1 [712 kB]\n",
      "Get:97 http://deb.debian.org/debian buster/main amd64 libfakeroot amd64 1.23-1 [45.9 kB]\n",
      "Get:98 http://deb.debian.org/debian buster/main amd64 fakeroot amd64 1.23-1 [85.8 kB]\n",
      "Get:99 http://deb.debian.org/debian buster/main amd64 libglib2.0-0 amd64 2.58.3-2+deb10u2 [1258 kB]\n",
      "Get:100 http://deb.debian.org/debian buster/main amd64 libgirepository-1.0-1 amd64 1.58.3-2 [92.8 kB]\n",
      "Get:101 http://deb.debian.org/debian buster/main amd64 gir1.2-glib-2.0 amd64 1.58.3-2 [143 kB]\n",
      "Get:102 http://deb.debian.org/debian buster/main amd64 gnupg-l10n all 2.2.12-1+deb10u1 [1010 kB]\n",
      "Get:103 http://deb.debian.org/debian buster/main amd64 gnupg-utils amd64 2.2.12-1+deb10u1 [861 kB]\n",
      "Get:104 http://deb.debian.org/debian buster/main amd64 gpg amd64 2.2.12-1+deb10u1 [865 kB]\n",
      "Get:105 http://deb.debian.org/debian buster/main amd64 pinentry-curses amd64 1.1.0-2 [64.5 kB]\n",
      "Get:106 http://deb.debian.org/debian buster/main amd64 gpg-agent amd64 2.2.12-1+deb10u1 [617 kB]\n",
      "Get:107 http://deb.debian.org/debian buster/main amd64 gpg-wks-client amd64 2.2.12-1+deb10u1 [485 kB]\n",
      "Get:108 http://deb.debian.org/debian buster/main amd64 gpg-wks-server amd64 2.2.12-1+deb10u1 [478 kB]\n",
      "Get:109 http://deb.debian.org/debian buster/main amd64 gpgsm amd64 2.2.12-1+deb10u1 [604 kB]\n",
      "Get:110 http://deb.debian.org/debian buster/main amd64 gnupg all 2.2.12-1+deb10u1 [715 kB]\n",
      "Get:111 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-perl all 1.19.03-2 [47.9 kB]\n",
      "Get:112 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-xs-perl amd64 0.04-5+b1 [11.8 kB]\n",
      "Get:113 http://deb.debian.org/debian buster/main amd64 libalgorithm-merge-perl all 0.08-3 [12.7 kB]\n",
      "Get:114 http://deb.debian.org/debian buster/main amd64 libexpat1-dev amd64 2.2.6-2+deb10u1 [153 kB]\n",
      "Get:115 http://deb.debian.org/debian buster/main amd64 libfile-fcntllock-perl amd64 0.22-3+b5 [35.4 kB]\n",
      "Get:116 http://deb.debian.org/debian buster/main amd64 libglib2.0-data all 2.58.3-2+deb10u2 [1110 kB]\n",
      "Get:117 http://deb.debian.org/debian buster/main amd64 libicu63 amd64 63.1-6+deb10u1 [8300 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:118 http://deb.debian.org/debian buster/main amd64 libpython2.7 amd64 2.7.16-2+deb10u1 [1036 kB]\n",
      "Get:119 http://deb.debian.org/debian buster/main amd64 libpython2.7-dev amd64 2.7.16-2+deb10u1 [31.6 MB]\n",
      "Get:120 http://deb.debian.org/debian buster/main amd64 libpython2-dev amd64 2.7.16-1 [20.9 kB]\n",
      "Get:121 http://deb.debian.org/debian buster/main amd64 libpython-dev amd64 2.7.16-1 [20.9 kB]\n",
      "Get:122 http://deb.debian.org/debian buster/main amd64 libpython3.7 amd64 3.7.3-2+deb10u2 [1498 kB]\n",
      "Get:123 http://deb.debian.org/debian buster/main amd64 libpython3.7-dev amd64 3.7.3-2+deb10u2 [48.4 MB]\n",
      "Get:124 http://deb.debian.org/debian buster/main amd64 libpython3-dev amd64 3.7.3-1 [20.1 kB]\n",
      "Get:125 http://deb.debian.org/debian buster/main amd64 libsasl2-modules amd64 2.1.27+dfsg-1+deb10u1 [104 kB]\n",
      "Get:126 http://deb.debian.org/debian buster/main amd64 libxml2 amd64 2.9.4+dfsg1-7+b3 [687 kB]\n",
      "Get:127 http://deb.debian.org/debian buster/main amd64 manpages-dev all 4.16-2 [2232 kB]\n",
      "Get:128 http://deb.debian.org/debian buster/main amd64 publicsuffix all 20190415.1030-1 [116 kB]\n",
      "Get:129 http://deb.debian.org/debian buster/main amd64 python2.7-dev amd64 2.7.16-2+deb10u1 [294 kB]\n",
      "Get:130 http://deb.debian.org/debian buster/main amd64 python2-dev amd64 2.7.16-1 [1212 B]\n",
      "Get:131 http://deb.debian.org/debian buster/main amd64 python-dev amd64 2.7.16-1 [1192 B]\n",
      "Get:132 http://deb.debian.org/debian buster/main amd64 python-pip-whl all 18.1-5 [1591 kB]\n",
      "Get:133 http://deb.debian.org/debian buster/main amd64 python-psutil amd64 5.5.1-1 [166 kB]\n",
      "Get:134 http://deb.debian.org/debian buster/main amd64 python3-asn1crypto all 0.24.0-1 [78.2 kB]\n",
      "Get:135 http://deb.debian.org/debian buster/main amd64 python3-cffi-backend amd64 1.12.2-1 [79.7 kB]\n",
      "Get:136 http://deb.debian.org/debian buster/main amd64 python3-crypto amd64 2.6.1-9+b1 [263 kB]\n",
      "Get:137 http://deb.debian.org/debian buster/main amd64 python3-six all 1.12.0-1 [15.7 kB]\n",
      "Get:138 http://deb.debian.org/debian buster/main amd64 python3-cryptography amd64 2.6.1-3+deb10u2 [219 kB]\n",
      "Get:139 http://deb.debian.org/debian buster/main amd64 python3-dbus amd64 1.2.8-3 [103 kB]\n",
      "Get:140 http://deb.debian.org/debian buster/main amd64 python3.7-dev amd64 3.7.3-2+deb10u2 [510 kB]\n",
      "Get:141 http://deb.debian.org/debian buster/main amd64 python3-dev amd64 3.7.3-1 [1264 B]\n",
      "Get:142 http://deb.debian.org/debian buster/main amd64 python3-entrypoints all 0.3-1 [5508 B]\n",
      "Get:143 http://deb.debian.org/debian buster/main amd64 python3-gi amd64 3.30.4-1 [180 kB]\n",
      "Get:144 http://deb.debian.org/debian buster/main amd64 python3-secretstorage all 2.3.1-2 [14.2 kB]\n",
      "Get:145 http://deb.debian.org/debian buster/main amd64 python3-keyring all 17.1.1-1 [43.1 kB]\n",
      "Get:146 http://deb.debian.org/debian buster/main amd64 python3-keyrings.alt all 3.1.1-1 [18.2 kB]\n",
      "Get:147 http://deb.debian.org/debian buster/main amd64 python3-pip all 18.1-5 [171 kB]\n",
      "Get:148 http://deb.debian.org/debian buster/main amd64 python3-pkg-resources all 40.8.0-1 [153 kB]\n",
      "Get:149 http://deb.debian.org/debian buster/main amd64 python3-setuptools all 40.8.0-1 [306 kB]\n",
      "Get:150 http://deb.debian.org/debian buster/main amd64 python3-wheel all 0.32.3-2 [19.4 kB]\n",
      "Get:151 http://deb.debian.org/debian buster/main amd64 python3-xdg all 0.25-5 [35.9 kB]\n",
      "Get:152 http://deb.debian.org/debian buster/main amd64 shared-mime-info amd64 1.10-1 [766 kB]\n",
      "Get:153 http://deb.debian.org/debian buster/main amd64 unzip amd64 6.0-23+deb10u1 [172 kB]\n",
      "Get:154 http://deb.debian.org/debian buster/main amd64 xdg-user-dirs amd64 0.17-2 [53.8 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 178 MB in 2s (85.8 MB/s)\n",
      "Selecting previously unselected package perl-modules-5.28.\n",
      "(Reading database ... 6889 files and directories currently installed.)\n",
      "Preparing to unpack .../00-perl-modules-5.28_5.28.1-6+deb10u1_all.deb ...\n",
      "Unpacking perl-modules-5.28 (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libgdbm6:amd64.\n",
      "Preparing to unpack .../01-libgdbm6_1.18.1-4_amd64.deb ...\n",
      "Unpacking libgdbm6:amd64 (1.18.1-4) ...\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\n",
      "Preparing to unpack .../02-libgdbm-compat4_1.18.1-4_amd64.deb ...\n",
      "Unpacking libgdbm-compat4:amd64 (1.18.1-4) ...\n",
      "Selecting previously unselected package libperl5.28:amd64.\n",
      "Preparing to unpack .../03-libperl5.28_5.28.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking libperl5.28:amd64 (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../04-perl_5.28.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking perl (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\n",
      "Preparing to unpack .../05-libpython2.7-minimal_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2.7-minimal.\n",
      "Preparing to unpack .../06-python2.7-minimal_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2-minimal.\n",
      "Preparing to unpack .../07-python2-minimal_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python-minimal.\n",
      "Preparing to unpack .../08-python-minimal_2.7.16-1_amd64.deb ...\n",
      "Unpacking python-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package mime-support.\n",
      "Preparing to unpack .../09-mime-support_3.62_all.deb ...\n",
      "Unpacking mime-support (3.62) ...\n",
      "Selecting previously unselected package libexpat1:amd64.\n",
      "Preparing to unpack .../10-libexpat1_2.2.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.2.6-2+deb10u1) ...\n",
      "Selecting previously unselected package readline-common.\n",
      "Preparing to unpack .../11-readline-common_7.0-5_all.deb ...\n",
      "Unpacking readline-common (7.0-5) ...\n",
      "Selecting previously unselected package libreadline7:amd64.\n",
      "Preparing to unpack .../12-libreadline7_7.0-5_amd64.deb ...\n",
      "Unpacking libreadline7:amd64 (7.0-5) ...\n",
      "Selecting previously unselected package libsqlite3-0:amd64.\n",
      "Preparing to unpack .../13-libsqlite3-0_3.27.2-3_amd64.deb ...\n",
      "Unpacking libsqlite3-0:amd64 (3.27.2-3) ...\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\n",
      "Preparing to unpack .../14-libpython2.7-stdlib_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2.7.\n",
      "Preparing to unpack .../15-python2.7_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2-stdlib:amd64.\n",
      "Preparing to unpack .../16-libpython2-stdlib_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython2-stdlib:amd64 (2.7.16-1) ...\n",
      "Selecting previously unselected package libpython-stdlib:amd64.\n",
      "Preparing to unpack .../17-libpython-stdlib_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up python2.7-minimal (2.7.16-2+deb10u1) ...\n",
      "Linking and byte-compiling packages for runtime python2.7...\n",
      "Setting up python2-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python2.\n",
      "(Reading database ... 9661 files and directories currently installed.)\n",
      "Preparing to unpack .../python2_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2 (2.7.16-1) ...\n",
      "Setting up python-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python.\n",
      "(Reading database ... 9694 files and directories currently installed.)\n",
      "Preparing to unpack .../python_2.7.16-1_amd64.deb ...\n",
      "Unpacking python (2.7.16-1) ...\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "Preparing to unpack .../liblocale-gettext-perl_1.07-3+b4_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-3+b4) ...\n",
      "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
      "Preparing to unpack .../libpython3.7-minimal_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-minimal:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3.7-minimal.\n",
      "Preparing to unpack .../python3.7-minimal_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7-minimal (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython3.7-minimal:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libexpat1:amd64 (2.2.6-2+deb10u1) ...\n",
      "Setting up python3.7-minimal (3.7.3-2+deb10u2) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package python3-minimal.\n",
      "(Reading database ... 9963 files and directories currently installed.)\n",
      "Preparing to unpack .../python3-minimal_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3-minimal (3.7.3-1) ...\n",
      "Selecting previously unselected package libmpdec2:amd64.\n",
      "Preparing to unpack .../libmpdec2_2.4.2-2_amd64.deb ...\n",
      "Unpacking libmpdec2:amd64 (2.4.2-2) ...\n",
      "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
      "Preparing to unpack .../libpython3.7-stdlib_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-stdlib:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3.7.\n",
      "Preparing to unpack .../python3.7_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libpython3-stdlib:amd64.\n",
      "Preparing to unpack .../libpython3-stdlib_3.7.3-1_amd64.deb ...\n",
      "Unpacking libpython3-stdlib:amd64 (3.7.3-1) ...\n",
      "Setting up python3-minimal (3.7.3-1) ...\n",
      "Selecting previously unselected package python3.\n",
      "(Reading database ... 10375 files and directories currently installed.)\n",
      "Preparing to unpack .../000-python3_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3 (3.7.3-1) ...\n",
      "Selecting previously unselected package netbase.\n",
      "Preparing to unpack .../001-netbase_5.6_all.deb ...\n",
      "Unpacking netbase (5.6) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../002-bzip2_1.0.6-9.2~deb10u1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.6-9.2~deb10u1) ...\n",
      "Selecting previously unselected package libapparmor1:amd64.\n",
      "Preparing to unpack .../003-libapparmor1_2.13.2-10_amd64.deb ...\n",
      "Unpacking libapparmor1:amd64 (2.13.2-10) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../004-libdbus-1-3_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package dbus.\n",
      "Preparing to unpack .../005-dbus_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking dbus (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package libmagic-mgc.\n",
      "Preparing to unpack .../006-libmagic-mgc_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking libmagic-mgc (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package libmagic1:amd64.\n",
      "Preparing to unpack .../007-libmagic1_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking libmagic1:amd64 (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package file.\n",
      "Preparing to unpack .../008-file_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking file (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package krb5-locales.\n",
      "Preparing to unpack .../009-krb5-locales_1.17-3_all.deb ...\n",
      "Unpacking krb5-locales (1.17-3) ...\n",
      "Selecting previously unselected package manpages.\n",
      "Preparing to unpack .../010-manpages_4.16-2_all.deb ...\n",
      "Unpacking manpages (4.16-2) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../011-xz-utils_5.2.4-1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.4-1) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../012-binutils-common_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.31.1-16) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../013-libbinutils_2.31.1-16_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.31.1-16) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../014-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../015-binutils_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils (2.31.1-16) ...\n",
      "Selecting previously unselected package libc-dev-bin.\n",
      "Preparing to unpack .../016-libc-dev-bin_2.28-10_amd64.deb ...\n",
      "Unpacking libc-dev-bin (2.28-10) ...\n",
      "Selecting previously unselected package linux-libc-dev:amd64.\n",
      "Preparing to unpack .../017-linux-libc-dev_4.19.132-1_amd64.deb ...\n",
      "Unpacking linux-libc-dev:amd64 (4.19.132-1) ...\n",
      "Selecting previously unselected package libc6-dev:amd64.\n",
      "Preparing to unpack .../018-libc6-dev_2.28-10_amd64.deb ...\n",
      "Unpacking libc6-dev:amd64 (2.28-10) ...\n",
      "Selecting previously unselected package libisl19:amd64.\n",
      "Preparing to unpack .../019-libisl19_0.20-2_amd64.deb ...\n",
      "Unpacking libisl19:amd64 (0.20-2) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../020-libmpfr6_4.0.2-1_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.0.2-1) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../021-libmpc3_1.1.0-1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package cpp-8.\n",
      "Preparing to unpack .../022-cpp-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking cpp-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../023-cpp_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking cpp (4:8.3.0-1) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../024-libcc1-0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../025-libgomp1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libgomp1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../026-libitm1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../027-libatomic1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libasan5:amd64.\n",
      "Preparing to unpack .../028-libasan5_8.3.0-6_amd64.deb ...\n",
      "Unpacking libasan5:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../029-liblsan0_8.3.0-6_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../030-libtsan0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libtsan0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../031-libubsan1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libmpx2:amd64.\n",
      "Preparing to unpack .../032-libmpx2_8.3.0-6_amd64.deb ...\n",
      "Unpacking libmpx2:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../033-libquadmath0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libgcc-8-dev:amd64.\n",
      "Preparing to unpack .../034-libgcc-8-dev_8.3.0-6_amd64.deb ...\n",
      "Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package gcc-8.\n",
      "Preparing to unpack .../035-gcc-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking gcc-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../036-gcc_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking gcc (4:8.3.0-1) ...\n",
      "Selecting previously unselected package libstdc++-8-dev:amd64.\n",
      "Preparing to unpack .../037-libstdc++-8-dev_8.3.0-6_amd64.deb ...\n",
      "Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package g++-8.\n",
      "Preparing to unpack .../038-g++-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking g++-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../039-g++_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking g++ (4:8.3.0-1) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../040-make_4.2.1-1.2_amd64.deb ...\n",
      "Unpacking make (4.2.1-1.2) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../041-libdpkg-perl_1.19.7_all.deb ...\n",
      "Unpacking libdpkg-perl (1.19.7) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../042-patch_2.7.6-3+deb10u1_amd64.deb ...\n",
      "Unpacking patch (2.7.6-3+deb10u1) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../043-dpkg-dev_1.19.7_all.deb ...\n",
      "Unpacking dpkg-dev (1.19.7) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../044-build-essential_12.6_amd64.deb ...\n",
      "Unpacking build-essential (12.6) ...\n",
      "Selecting previously unselected package libkeyutils1:amd64.\n",
      "Preparing to unpack .../045-libkeyutils1_1.6-6_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.6-6) ...\n",
      "Selecting previously unselected package libkrb5support0:amd64.\n",
      "Preparing to unpack .../046-libkrb5support0_1.17-3_amd64.deb ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking libkrb5support0:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libk5crypto3:amd64.\n",
      "Preparing to unpack .../047-libk5crypto3_1.17-3_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libkrb5-3:amd64.\n",
      "Preparing to unpack .../048-libkrb5-3_1.17-3_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libgssapi-krb5-2:amd64.\n",
      "Preparing to unpack .../049-libgssapi-krb5-2_1.17-3_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../050-libsasl2-modules-db_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../051-libsasl2-2_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libldap-common.\n",
      "Preparing to unpack .../052-libldap-common_2.4.47+dfsg-3+deb10u2_all.deb ...\n",
      "Unpacking libldap-common (2.4.47+dfsg-3+deb10u2) ...\n",
      "Selecting previously unselected package libldap-2.4-2:amd64.\n",
      "Preparing to unpack .../053-libldap-2.4-2_2.4.47+dfsg-3+deb10u2_amd64.deb ...\n",
      "Unpacking libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u2) ...\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\n",
      "Preparing to unpack .../054-libnghttp2-14_1.36.0-2+deb10u1_amd64.deb ...\n",
      "Unpacking libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\n",
      "Selecting previously unselected package libpsl5:amd64.\n",
      "Preparing to unpack .../055-libpsl5_0.20.2-2_amd64.deb ...\n",
      "Unpacking libpsl5:amd64 (0.20.2-2) ...\n",
      "Selecting previously unselected package librtmp1:amd64.\n",
      "Preparing to unpack .../056-librtmp1_2.4+20151223.gitfa8646d.1-2_amd64.deb ...\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\n",
      "Selecting previously unselected package libssh2-1:amd64.\n",
      "Preparing to unpack .../057-libssh2-1_1.8.0-2.1_amd64.deb ...\n",
      "Unpacking libssh2-1:amd64 (1.8.0-2.1) ...\n",
      "Selecting previously unselected package libcurl4:amd64.\n",
      "Preparing to unpack .../058-libcurl4_7.64.0-4+deb10u1_amd64.deb ...\n",
      "Unpacking libcurl4:amd64 (7.64.0-4+deb10u1) ...\n",
      "Selecting previously unselected package curl.\n",
      "Preparing to unpack .../059-curl_7.64.0-4+deb10u1_amd64.deb ...\n",
      "Unpacking curl (7.64.0-4+deb10u1) ...\n",
      "Selecting previously unselected package python3-lib2to3.\n",
      "Preparing to unpack .../060-python3-lib2to3_3.7.3-1_all.deb ...\n",
      "Unpacking python3-lib2to3 (3.7.3-1) ...\n",
      "Selecting previously unselected package python3-distutils.\n",
      "Preparing to unpack .../061-python3-distutils_3.7.3-1_all.deb ...\n",
      "Unpacking python3-distutils (3.7.3-1) ...\n",
      "Selecting previously unselected package dh-python.\n",
      "Preparing to unpack .../062-dh-python_3.20190308_all.deb ...\n",
      "Unpacking dh-python (3.20190308) ...\n",
      "Selecting previously unselected package libassuan0:amd64.\n",
      "Preparing to unpack .../063-libassuan0_2.5.2-1_amd64.deb ...\n",
      "Unpacking libassuan0:amd64 (2.5.2-1) ...\n",
      "Selecting previously unselected package gpgconf.\n",
      "Preparing to unpack .../064-gpgconf_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpgconf (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../065-libksba8_1.3.5-2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.3.5-2) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../066-libnpth0_1.6-1_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-1) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../067-dirmngr_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../068-libfakeroot_1.23-1_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.23-1) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../069-fakeroot_1.23-1_amd64.deb ...\n",
      "Unpacking fakeroot (1.23-1) ...\n",
      "Selecting previously unselected package libglib2.0-0:amd64.\n",
      "Preparing to unpack .../070-libglib2.0-0_2.58.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.58.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
      "Preparing to unpack .../071-libgirepository-1.0-1_1.58.3-2_amd64.deb ...\n",
      "Unpacking libgirepository-1.0-1:amd64 (1.58.3-2) ...\n",
      "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
      "Preparing to unpack .../072-gir1.2-glib-2.0_1.58.3-2_amd64.deb ...\n",
      "Unpacking gir1.2-glib-2.0:amd64 (1.58.3-2) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../073-gnupg-l10n_2.2.12-1+deb10u1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../074-gnupg-utils_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg.\n",
      "Preparing to unpack .../075-gpg_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../076-pinentry-curses_1.1.0-2_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.1.0-2) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../077-gpg-agent_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../078-gpg-wks-client_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../079-gpg-wks-server_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../080-gpgsm_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../081-gnupg_2.2.12-1+deb10u1_all.deb ...\n",
      "Unpacking gnupg (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../082-libalgorithm-diff-perl_1.19.03-2_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl.\n",
      "Preparing to unpack .../083-libalgorithm-diff-xs-perl_0.04-5+b1_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl (0.04-5+b1) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../084-libalgorithm-merge-perl_0.08-3_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-3) ...\n",
      "Selecting previously unselected package libexpat1-dev:amd64.\n",
      "Preparing to unpack .../085-libexpat1-dev_2.2.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libexpat1-dev:amd64 (2.2.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../086-libfile-fcntllock-perl_0.22-3+b5_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-3+b5) ...\n",
      "Selecting previously unselected package libglib2.0-data.\n",
      "Preparing to unpack .../087-libglib2.0-data_2.58.3-2+deb10u2_all.deb ...\n",
      "Unpacking libglib2.0-data (2.58.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libicu63:amd64.\n",
      "Preparing to unpack .../088-libicu63_63.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking libicu63:amd64 (63.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7:amd64.\n",
      "Preparing to unpack .../089-libpython2.7_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7-dev:amd64.\n",
      "Preparing to unpack .../090-libpython2.7-dev_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-dev:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2-dev:amd64.\n",
      "Preparing to unpack .../091-libpython2-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython2-dev:amd64 (2.7.16-1) ...\n",
      "Selecting previously unselected package libpython-dev:amd64.\n",
      "Preparing to unpack .../092-libpython-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython-dev:amd64 (2.7.16-1) ...\n",
      "Selecting previously unselected package libpython3.7:amd64.\n",
      "Preparing to unpack .../093-libpython3.7_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libpython3.7-dev:amd64.\n",
      "Preparing to unpack .../094-libpython3.7-dev_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-dev:amd64 (3.7.3-2+deb10u2) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libpython3-dev:amd64.\n",
      "Preparing to unpack .../095-libpython3-dev_3.7.3-1_amd64.deb ...\n",
      "Unpacking libpython3-dev:amd64 (3.7.3-1) ...\n",
      "Selecting previously unselected package libsasl2-modules:amd64.\n",
      "Preparing to unpack .../096-libsasl2-modules_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-modules:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libxml2:amd64.\n",
      "Preparing to unpack .../097-libxml2_2.9.4+dfsg1-7+b3_amd64.deb ...\n",
      "Unpacking libxml2:amd64 (2.9.4+dfsg1-7+b3) ...\n",
      "Selecting previously unselected package manpages-dev.\n",
      "Preparing to unpack .../098-manpages-dev_4.16-2_all.deb ...\n",
      "Unpacking manpages-dev (4.16-2) ...\n",
      "Selecting previously unselected package publicsuffix.\n",
      "Preparing to unpack .../099-publicsuffix_20190415.1030-1_all.deb ...\n",
      "Unpacking publicsuffix (20190415.1030-1) ...\n",
      "Selecting previously unselected package python2.7-dev.\n",
      "Preparing to unpack .../100-python2.7-dev_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7-dev (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2-dev.\n",
      "Preparing to unpack .../101-python2-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2-dev (2.7.16-1) ...\n",
      "Selecting previously unselected package python-dev.\n",
      "Preparing to unpack .../102-python-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking python-dev (2.7.16-1) ...\n",
      "Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../103-python-pip-whl_18.1-5_all.deb ...\n",
      "Unpacking python-pip-whl (18.1-5) ...\n",
      "Selecting previously unselected package python-psutil.\n",
      "Preparing to unpack .../104-python-psutil_5.5.1-1_amd64.deb ...\n",
      "Unpacking python-psutil (5.5.1-1) ...\n",
      "Selecting previously unselected package python3-asn1crypto.\n",
      "Preparing to unpack .../105-python3-asn1crypto_0.24.0-1_all.deb ...\n",
      "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
      "Selecting previously unselected package python3-cffi-backend.\n",
      "Preparing to unpack .../106-python3-cffi-backend_1.12.2-1_amd64.deb ...\n",
      "Unpacking python3-cffi-backend (1.12.2-1) ...\n",
      "Selecting previously unselected package python3-crypto.\n",
      "Preparing to unpack .../107-python3-crypto_2.6.1-9+b1_amd64.deb ...\n",
      "Unpacking python3-crypto (2.6.1-9+b1) ...\n",
      "Selecting previously unselected package python3-six.\n",
      "Preparing to unpack .../108-python3-six_1.12.0-1_all.deb ...\n",
      "Unpacking python3-six (1.12.0-1) ...\n",
      "Selecting previously unselected package python3-cryptography.\n",
      "Preparing to unpack .../109-python3-cryptography_2.6.1-3+deb10u2_amd64.deb ...\n",
      "Unpacking python3-cryptography (2.6.1-3+deb10u2) ...\n",
      "Selecting previously unselected package python3-dbus.\n",
      "Preparing to unpack .../110-python3-dbus_1.2.8-3_amd64.deb ...\n",
      "Unpacking python3-dbus (1.2.8-3) ...\n",
      "Selecting previously unselected package python3.7-dev.\n",
      "Preparing to unpack .../111-python3.7-dev_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7-dev (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3-dev.\n",
      "Preparing to unpack .../112-python3-dev_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3-dev (3.7.3-1) ...\n",
      "Selecting previously unselected package python3-entrypoints.\n",
      "Preparing to unpack .../113-python3-entrypoints_0.3-1_all.deb ...\n",
      "Unpacking python3-entrypoints (0.3-1) ...\n",
      "Selecting previously unselected package python3-gi.\n",
      "Preparing to unpack .../114-python3-gi_3.30.4-1_amd64.deb ...\n",
      "Unpacking python3-gi (3.30.4-1) ...\n",
      "Selecting previously unselected package python3-secretstorage.\n",
      "Preparing to unpack .../115-python3-secretstorage_2.3.1-2_all.deb ...\n",
      "Unpacking python3-secretstorage (2.3.1-2) ...\n",
      "Selecting previously unselected package python3-keyring.\n",
      "Preparing to unpack .../116-python3-keyring_17.1.1-1_all.deb ...\n",
      "Unpacking python3-keyring (17.1.1-1) ...\n",
      "Selecting previously unselected package python3-keyrings.alt.\n",
      "Preparing to unpack .../117-python3-keyrings.alt_3.1.1-1_all.deb ...\n",
      "Unpacking python3-keyrings.alt (3.1.1-1) ...\n",
      "Selecting previously unselected package python3-pip.\n",
      "Preparing to unpack .../118-python3-pip_18.1-5_all.deb ...\n",
      "Unpacking python3-pip (18.1-5) ...\n",
      "Selecting previously unselected package python3-pkg-resources.\n",
      "Preparing to unpack .../119-python3-pkg-resources_40.8.0-1_all.deb ...\n",
      "Unpacking python3-pkg-resources (40.8.0-1) ...\n",
      "Selecting previously unselected package python3-setuptools.\n",
      "Preparing to unpack .../120-python3-setuptools_40.8.0-1_all.deb ...\n",
      "Unpacking python3-setuptools (40.8.0-1) ...\n",
      "Selecting previously unselected package python3-wheel.\n",
      "Preparing to unpack .../121-python3-wheel_0.32.3-2_all.deb ...\n",
      "Unpacking python3-wheel (0.32.3-2) ...\n",
      "Selecting previously unselected package python3-xdg.\n",
      "Preparing to unpack .../122-python3-xdg_0.25-5_all.deb ...\n",
      "Unpacking python3-xdg (0.25-5) ...\n",
      "Selecting previously unselected package shared-mime-info.\n",
      "Preparing to unpack .../123-shared-mime-info_1.10-1_amd64.deb ...\n",
      "Unpacking shared-mime-info (1.10-1) ...\n",
      "Selecting previously unselected package unzip.\n",
      "Preparing to unpack .../124-unzip_6.0-23+deb10u1_amd64.deb ...\n",
      "Unpacking unzip (6.0-23+deb10u1) ...\n",
      "Selecting previously unselected package xdg-user-dirs.\n",
      "Preparing to unpack .../125-xdg-user-dirs_0.17-2_amd64.deb ...\n",
      "Unpacking xdg-user-dirs (0.17-2) ...\n",
      "Setting up perl-modules-5.28 (5.28.1-6+deb10u1) ...\n",
      "Setting up libksba8:amd64 (1.3.5-2) ...\n",
      "Setting up libkeyutils1:amd64 (1.6-6) ...\n",
      "Setting up libapparmor1:amd64 (2.13.2-10) ...\n",
      "Setting up libpsl5:amd64 (0.20.2-2) ...\n",
      "Setting up mime-support (3.62) ...\n",
      "Setting up xdg-user-dirs (0.17-2) ...\n",
      "Setting up libmagic-mgc (1:5.35-4+deb10u1) ...\n",
      "Setting up libglib2.0-0:amd64 (2.58.3-2+deb10u2) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up manpages (4.16-2) ...\n",
      "Setting up unzip (6.0-23+deb10u1) ...\n",
      "Setting up libsqlite3-0:amd64 (3.27.2-3) ...\n",
      "Setting up libsasl2-modules:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up binutils-common:amd64 (2.31.1-16) ...\n",
      "Setting up libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\n",
      "Setting up libmagic1:amd64 (1:5.35-4+deb10u1) ...\n",
      "Setting up linux-libc-dev:amd64 (4.19.132-1) ...\n",
      "Setting up libnpth0:amd64 (1.6-1) ...\n",
      "Setting up krb5-locales (1.17-3) ...\n",
      "Setting up file (1:5.35-4+deb10u1) ...\n",
      "Setting up libassuan0:amd64 (2.5.2-1) ...\n",
      "Setting up libgomp1:amd64 (8.3.0-6) ...\n",
      "Setting up bzip2 (1.0.6-9.2~deb10u1) ...\n",
      "Setting up libldap-common (2.4.47+dfsg-3+deb10u2) ...\n",
      "Setting up libicu63:amd64 (63.1-6+deb10u1) ...\n",
      "Setting up libfakeroot:amd64 (1.23-1) ...\n",
      "Setting up libkrb5support0:amd64 (1.17-3) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up fakeroot (1.23-1) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up libasan5:amd64 (8.3.0-6) ...\n",
      "Setting up libglib2.0-data (2.58.3-2+deb10u2) ...\n",
      "Setting up make (4.2.1-1.2) ...\n",
      "Setting up libmpfr6:amd64 (4.0.2-1) ...\n",
      "Setting up gnupg-l10n (2.2.12-1+deb10u1) ...\n",
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Setting up dbus (1.12.20-0+deb10u1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up xz-utils (5.2.4-1) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (8.3.0-6) ...\n",
      "Setting up libmpc3:amd64 (1.1.0-1) ...\n",
      "Setting up libatomic1:amd64 (8.3.0-6) ...\n",
      "Setting up patch (2.7.6-3+deb10u1) ...\n",
      "Setting up libk5crypto3:amd64 (1.17-3) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up libmpx2:amd64 (8.3.0-6) ...\n",
      "Setting up libubsan1:amd64 (8.3.0-6) ...\n",
      "Setting up libisl19:amd64 (0.20-2) ...\n",
      "Setting up libgirepository-1.0-1:amd64 (1.58.3-2) ...\n",
      "Setting up libssh2-1:amd64 (1.8.0-2.1) ...\n",
      "Setting up netbase (5.6) ...\n",
      "Setting up python-pip-whl (18.1-5) ...\n",
      "Setting up libkrb5-3:amd64 (1.17-3) ...\n",
      "Setting up libmpdec2:amd64 (2.4.2-2) ...\n",
      "Setting up libbinutils:amd64 (2.31.1-16) ...\n",
      "Setting up cpp-8 (8.3.0-6) ...\n",
      "Setting up libc-dev-bin (2.28-10) ...\n",
      "Setting up readline-common (7.0-5) ...\n",
      "Setting up publicsuffix (20190415.1030-1) ...\n",
      "Setting up libxml2:amd64 (2.9.4+dfsg1-7+b3) ...\n",
      "Setting up libcc1-0:amd64 (8.3.0-6) ...\n",
      "Setting up liblocale-gettext-perl (1.07-3+b4) ...\n",
      "Setting up liblsan0:amd64 (8.3.0-6) ...\n",
      "Setting up libitm1:amd64 (8.3.0-6) ...\n",
      "Setting up libreadline7:amd64 (7.0-5) ...\n",
      "Setting up libgdbm6:amd64 (1.18.1-4) ...\n",
      "Setting up gnupg-utils (2.2.12-1+deb10u1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...\n",
      "Setting up libtsan0:amd64 (8.3.0-6) ...\n",
      "Setting up pinentry-curses (1.1.0-2) ...\n",
      "Setting up manpages-dev (4.16-2) ...\n",
      "Setting up libpython3.7-stdlib:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython3.7:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u2) ...\n",
      "Setting up binutils (2.31.1-16) ...\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up shared-mime-info (1.10-1) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.17-3) ...\n",
      "Setting up libgdbm-compat4:amd64 (1.18.1-4) ...\n",
      "Setting up gir1.2-glib-2.0:amd64 (1.58.3-2) ...\n",
      "Setting up libgcc-8-dev:amd64 (8.3.0-6) ...\n",
      "Setting up libperl5.28:amd64 (5.28.1-6+deb10u1) ...\n",
      "Setting up cpp (4:8.3.0-1) ...\n",
      "Setting up gpgconf (2.2.12-1+deb10u1) ...\n",
      "Setting up libcurl4:amd64 (7.64.0-4+deb10u1) ...\n",
      "Setting up libc6-dev:amd64 (2.28-10) ...\n",
      "Setting up curl (7.64.0-4+deb10u1) ...\n",
      "Setting up gpg (2.2.12-1+deb10u1) ...\n",
      "Setting up libpython3-stdlib:amd64 (3.7.3-1) ...\n",
      "Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...\n",
      "Setting up python3.7 (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython2.7:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up gcc-8 (8.3.0-6) ...\n",
      "Setting up gpg-agent (2.2.12-1+deb10u1) ...\n",
      "Setting up python2.7 (2.7.16-2+deb10u1) ...\n",
      "Setting up libpython2-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up gpgsm (2.2.12-1+deb10u1) ...\n",
      "Setting up python3 (3.7.3-1) ...\n",
      "running python rtupdate hooks for python3.7...\n",
      "running python post-rtupdate hooks for python3.7...\n",
      "Setting up python3-xdg (0.25-5) ...\n",
      "Setting up python3-wheel (0.32.3-2) ...\n",
      "Setting up python2 (2.7.16-1) ...\n",
      "Setting up gcc (4:8.3.0-1) ...\n",
      "Setting up python3-six (1.12.0-1) ...\n",
      "Setting up dirmngr (2.2.12-1+deb10u1) ...\n",
      "Setting up libpython-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up perl (5.28.1-6+deb10u1) ...\n",
      "Setting up libexpat1-dev:amd64 (2.2.6-2+deb10u1) ...\n",
      "Setting up python3-gi (3.30.4-1) ...\n",
      "Setting up libdpkg-perl (1.19.7) ...\n",
      "Setting up gpg-wks-server (2.2.12-1+deb10u1) ...\n",
      "Setting up g++-8 (8.3.0-6) ...\n",
      "Setting up python3-crypto (2.6.1-9+b1) ...\n",
      "Setting up python3-lib2to3 (3.7.3-1) ...\n",
      "Setting up python (2.7.16-1) ...\n",
      "Setting up python3-asn1crypto (0.24.0-1) ...\n",
      "Setting up python3-cffi-backend (1.12.2-1) ...\n",
      "Setting up python3-pkg-resources (40.8.0-1) ...\n",
      "Setting up python3-entrypoints (0.3-1) ...\n",
      "Setting up python3-distutils (3.7.3-1) ...\n",
      "Setting up dh-python (3.20190308) ...\n",
      "Setting up python3-dbus (1.2.8-3) ...\n",
      "Setting up libpython2.7-dev:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up python3-setuptools (40.8.0-1) ...\n",
      "Setting up gpg-wks-client (2.2.12-1+deb10u1) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-3+b5) ...\n",
      "Setting up libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Setting up libpython3.7-dev:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up python3.7-dev (3.7.3-2+deb10u2) ...\n",
      "Setting up dpkg-dev (1.19.7) ...\n",
      "Setting up python3-cryptography (2.6.1-3+deb10u2) ...\n",
      "Setting up python3-pip (18.1-5) ...\n",
      "Setting up python-psutil (5.5.1-1) ...\n",
      "Setting up g++ (4:8.3.0-1) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "Setting up python3-keyrings.alt (3.1.1-1) ...\n",
      "Setting up gnupg (2.2.12-1+deb10u1) ...\n",
      "Setting up build-essential (12.6) ...\n",
      "Setting up libpython2-dev:amd64 (2.7.16-1) ...\n",
      "Setting up libalgorithm-diff-xs-perl (0.04-5+b1) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-3) ...\n",
      "Setting up python2.7-dev (2.7.16-2+deb10u1) ...\n",
      "Setting up libpython3-dev:amd64 (3.7.3-1) ...\n",
      "Setting up python2-dev (2.7.16-1) ...\n",
      "Setting up libpython-dev:amd64 (2.7.16-1) ...\n",
      "Setting up python3-secretstorage (2.3.1-2) ...\n",
      "Setting up python3-dev (3.7.3-1) ...\n",
      "Setting up python3-keyring (17.1.1-1) ...\n",
      "Setting up python-dev (2.7.16-1) ...\n",
      "Processing triggers for libc-bin (2.28-10) ...\n",
      "Removing intermediate container a9a5c5b6668b\n",
      " ---> 5d4c740842cc\n",
      "Step 4/32 : RUN pip3 install py4j psutil==5.6.5 mleap==0.8.1 boto3\n",
      " ---> Running in 6fb2cb481ad4\n",
      "Collecting py4j\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "Collecting psutil==5.6.5\n",
      "  Downloading https://files.pythonhosted.org/packages/03/9a/95c4b3d0424426e5fd94b5302ff74cea44d5d4f53466e1228ac8e73e14b4/psutil-5.6.5.tar.gz (447kB)\n",
      "Collecting mleap==0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/17/486a3cf30695581f029ba618ee878252a9e9f859c48913e30a07d13c8a21/mleap-0.8.1.tar.gz\n",
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/6f/65f5d4074887789dfa71e182fa17a71667270a0bec3683bc18c8eb90db0a/boto3-1.14.45-py2.py3-none-any.whl (129kB)\n",
      "Collecting argparse>=1.1 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
      "Collecting nose-exclude>=0.5.0 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/cf/90c4be56bf11b7bc8801086d9445baf731aa36b8e8fc5791731e8e604dcd/nose-exclude-0.5.0.tar.gz\n",
      "Collecting numpy>=1.8.2 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/d1/90cd7e0b27ee86d77f5386d38b74520486100286d50772377791b6ef22ff/numpy-1.19.1-cp37-cp37m-manylinux1_x86_64.whl (13.4MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas>=0.18.1 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/94/b1/f77f49cc7cc538b247f30c2ae7e3a50f29e44f0b1af32ff4869d7de3c762/pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5MB)\n",
      "Collecting scikit-learn>=0.18.dev0 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
      "Collecting scipy>=0.13.0b1 (from mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/f9/f7a7e5009711579c72da2725174825e5056741bf4001815d097eef1b2e17/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from mleap==0.8.1) (1.12.0)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "Collecting botocore<1.18.0,>=1.17.45 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/3b/914d73c869846880305f3cf7d562b97e79ecf05df32ab57b5fb6f3ba149a/botocore-1.17.45-py2.py3-none-any.whl (6.5MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting nose (from nose-exclude>=0.5.0->mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "Collecting pytz>=2017.2 (from pandas>=0.18.1->mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl (510kB)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas>=0.18.1->mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.18.dev0->mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl (300kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.18.dev0->mleap==0.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\" (from botocore<1.18.0,>=1.17.45->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.18.0,>=1.17.45->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Building wheels for collected packages: psutil, mleap, nose-exclude\n",
      "  Running setup.py bdist_wheel for psutil: started\n",
      "  Running setup.py bdist_wheel for psutil: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/48/b6/72b7243c5caf65b7d5b460e9fad82b1256992284e870b7db59\n",
      "  Running setup.py bdist_wheel for mleap: started\n",
      "  Running setup.py bdist_wheel for mleap: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/a5/8d/7d021f2741ed8a7354e4fe19c1890e71ed719d681cd16cf292\n",
      "  Running setup.py bdist_wheel for nose-exclude: started\n",
      "  Running setup.py bdist_wheel for nose-exclude: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/b9/8f/764ed47b11e2e062ae8fe5f09d1c801a600292fdd9ba3477bb\n",
      "Successfully built psutil mleap nose-exclude\n",
      "Installing collected packages: py4j, psutil, argparse, nose, nose-exclude, numpy, pytz, python-dateutil, pandas, joblib, threadpoolctl, scipy, scikit-learn, mleap, urllib3, docutils, jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed argparse-1.4.0 boto3-1.14.45 botocore-1.17.45 docutils-0.15.2 jmespath-0.10.0 joblib-0.16.0 mleap-0.8.1 nose-1.3.7 nose-exclude-0.5.0 numpy-1.19.1 pandas-1.1.0 psutil-5.6.5 py4j-0.10.9 python-dateutil-2.8.1 pytz-2020.1 s3transfer-0.3.3 scikit-learn-0.23.2 scipy-1.5.2 threadpoolctl-2.1.0 urllib3-1.25.10\n",
      "Removing intermediate container 6fb2cb481ad4\n",
      " ---> be02c955870a\n",
      "Step 5/32 : RUN apt-get clean\n",
      " ---> Running in f20ab6ec322b\n",
      "Removing intermediate container f20ab6ec322b\n",
      " ---> aeb959a49476\n",
      "Step 6/32 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 52c7ae8026e3\n",
      "Removing intermediate container 52c7ae8026e3\n",
      " ---> c3d8761c4e1a\n",
      "Step 7/32 : ENV PYTHONHASHSEED 0\n",
      " ---> Running in f05e1553ece2\n",
      "Removing intermediate container f05e1553ece2\n",
      " ---> f8fb96936e5e\n",
      "Step 8/32 : ENV PYTHONIOENCODING UTF-8\n",
      " ---> Running in ef321c58d2bc\n",
      "Removing intermediate container ef321c58d2bc\n",
      " ---> 0a50a2b53134\n",
      "Step 9/32 : ENV PIP_DISABLE_PIP_VERSION_CHECK 1\n",
      " ---> Running in cb15d61855ba\n",
      "Removing intermediate container cb15d61855ba\n",
      " ---> 2b0638fd898f\n",
      "Step 10/32 : ENV HADOOP_VERSION 3.0.0\n",
      " ---> Running in 2a2ff4ff36a5\n",
      "Removing intermediate container 2a2ff4ff36a5\n",
      " ---> 588d41b74b7c\n",
      "Step 11/32 : ENV HADOOP_HOME /usr/hadoop-$HADOOP_VERSION\n",
      " ---> Running in b3d9d6dc8f3c\n",
      "Removing intermediate container b3d9d6dc8f3c\n",
      " ---> 562e8f28bda5\n",
      "Step 12/32 : ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\n",
      " ---> Running in 4ca39d322e13\n",
      "Removing intermediate container 4ca39d322e13\n",
      " ---> 491387dbee88\n",
      "Step 13/32 : ENV PATH $PATH:$HADOOP_HOME/bin\n",
      " ---> Running in 64e362ad81c9\n",
      "Removing intermediate container 64e362ad81c9\n",
      " ---> 06ed43b8bbd4\n",
      "Step 14/32 : RUN curl -sL --retry 3   \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"   | gunzip   | tar -x -C /usr/  && rm -rf $HADOOP_HOME/share/doc  && chown -R root:root $HADOOP_HOME\n",
      " ---> Running in 053273eddd74\n",
      "Removing intermediate container 053273eddd74\n",
      " ---> f72bd15ef66d\n",
      "Step 15/32 : ENV SPARK_VERSION 2.2.0\n",
      " ---> Running in 74079513e800\n",
      "Removing intermediate container 74079513e800\n",
      " ---> fb076435b561\n",
      "Step 16/32 : ENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop\n",
      " ---> Running in 6c36c27bcbf8\n",
      "Removing intermediate container 6c36c27bcbf8\n",
      " ---> c134cbb1c119\n",
      "Step 17/32 : ENV SPARK_HOME /usr/spark-${SPARK_VERSION}\n",
      " ---> Running in 86c44d7d812c\n",
      "Removing intermediate container 86c44d7d812c\n",
      " ---> e678930afe73\n",
      "Step 18/32 : ENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*:$SPARK_HOME/input_custom_jars/*\"\n",
      " ---> Running in ce86a36b2d0b\n",
      "Removing intermediate container ce86a36b2d0b\n",
      " ---> b77c05effa81\n",
      "Step 19/32 : ENV PATH $PATH:${SPARK_HOME}/bin\n",
      " ---> Running in 6a89ac0b4adc\n",
      "Removing intermediate container 6a89ac0b4adc\n",
      " ---> 455c80457f47\n",
      "Step 20/32 : RUN curl -sL --retry 3   \"https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\"   | gunzip   | tar x -C /usr/  && mv /usr/$SPARK_PACKAGE $SPARK_HOME  && chown -R root:root $SPARK_HOME\n",
      " ---> Running in a0e92337e634\n",
      "Removing intermediate container a0e92337e634\n",
      " ---> 329d412d1b14\n",
      "Step 21/32 : ENV PYSPARK_PYTHON=/usr/bin/python3\n",
      " ---> Running in 82b32a1c8f00\n",
      "Removing intermediate container 82b32a1c8f00\n",
      " ---> 67b3cdf38685\n",
      "Step 22/32 : ENV PATH=\"/usr/bin:/opt/program:${PATH}\"\n",
      " ---> Running in 98dd4b2ffc11\n",
      "Removing intermediate container 98dd4b2ffc11\n",
      " ---> da2c8ef9231a\n",
      "Step 23/32 : ENV YARN_RESOURCEMANAGER_USER=\"root\"\n",
      " ---> Running in 6ce0fc2ec75f\n",
      "Removing intermediate container 6ce0fc2ec75f\n",
      " ---> 4fc8518d5d82\n",
      "Step 24/32 : ENV YARN_NODEMANAGER_USER=\"root\"\n",
      " ---> Running in 1feafb4c2500\n",
      "Removing intermediate container 1feafb4c2500\n",
      " ---> 1dc180d78e80\n",
      "Step 25/32 : ENV HDFS_NAMENODE_USER=\"root\"\n",
      " ---> Running in 0aaa85819436\n",
      "Removing intermediate container 0aaa85819436\n",
      " ---> 44903d6afeb7\n",
      "Step 26/32 : ENV HDFS_DATANODE_USER=\"root\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> Running in db8df67399df\n",
      "Removing intermediate container db8df67399df\n",
      " ---> 6bd79aea9957\n",
      "Step 27/32 : ENV HDFS_SECONDARYNAMENODE_USER=\"root\"\n",
      " ---> Running in 936983e5726b\n",
      "Removing intermediate container 936983e5726b\n",
      " ---> 982e2f9817ed\n",
      "Step 28/32 : COPY program /opt/program\n",
      " ---> 021520dccaee\n",
      "Step 29/32 : RUN chmod +x /opt/program/submit\n",
      " ---> Running in 153d12754051\n",
      "Removing intermediate container 153d12754051\n",
      " ---> 62a484f6ee9b\n",
      "Step 30/32 : COPY hadoop-config /opt/hadoop-config\n",
      " ---> 368c07a96425\n",
      "Step 31/32 : WORKDIR $SPARK_HOME\n",
      " ---> Running in b23a7d0b1df0\n",
      "Removing intermediate container b23a7d0b1df0\n",
      " ---> 4bb53f53a8a9\n",
      "Step 32/32 : ENTRYPOINT [\"/opt/program/submit\"]\n",
      " ---> Running in f1941e83d967\n",
      "Removing intermediate container f1941e83d967\n",
      " ---> 490cdd58cf2a\n",
      "Successfully built 490cdd58cf2a\n",
      "Successfully tagged sagemaker-spark-example:latest\n",
      "/home/ec2-user/SageMaker/sagemaker-ml-workflow-with-apache-airflow\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/sagemaker-ml-workflow-with-apache-airflow/container\n",
    "!docker build -t sagemaker-spark-example .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-spark-example' already exists in the registry with id '452432741922'\n",
      "The push refers to repository [452432741922.dkr.ecr.us-east-1.amazonaws.com/sagemaker-spark-example]\n",
      "\n",
      "\u001b[1B622d5b24: Preparing \n",
      "\u001b[1B7a6f14a8: Preparing \n",
      "\u001b[1B51027859: Preparing \n",
      "\u001b[1B29112dff: Preparing \n",
      "\u001b[1Bb9b3e8c6: Preparing \n",
      "\u001b[1Bddc8bb51: Preparing \n",
      "\u001b[1B6d71e867: Preparing \n",
      "\u001b[1Bdee7661f: Preparing \n",
      "\u001b[1B2bbb24bf: Preparing \n",
      "\u001b[1B47855bc1: Preparing \n",
      "\u001b[1B8102614d: Preparing \n",
      "\u001b[1B52ed4cbd: Preparing \n",
      "\u001b[1B0fa5728d: Preparing \n",
      "\u001b[6B2bbb24bf: Pushed   490.3MB/481.8MB\u001b[14A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[12A\u001b[2K\u001b[9A\u001b[2K\u001b[14A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2Klatest: digest: sha256:0c10dc66c37a172547ed295c52a03efbf9847fa881fa25a3f5fb7d64bb12e44d size: 3262\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "ecr_repository = 'sagemaker-spark-example'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "spark_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $spark_repository_uri\n",
    "!docker push $spark_repository_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'452432741922.dkr.ecr.us-east-1.amazonaws.com/sagemaker-spark-example:latest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_repository_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "import boto3\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from mleap.pyspark.spark_support import SimpleSparkSerializer\n",
    "\n",
    "def csv_line(data):\n",
    "    r = ','.join(str(d) for d in data[1])\n",
    "    return str(data[0]) + \",\" + r\n",
    "\n",
    "\n",
    "def main():\n",
    "    spark = SparkSession.builder.appName(\"PySparkAbalone\").getOrCreate()\n",
    "    \n",
    "    # Convert command line args into a map of args\n",
    "    args_iter = iter(sys.argv[1:])\n",
    "    args = dict(zip(args_iter, args_iter))\n",
    "    \n",
    "    # This is needed to save RDDs which is the only way to write nested Dataframes into CSV format\n",
    "    spark.sparkContext._jsc.hadoopConfiguration().set(\"mapred.output.committer.class\",\n",
    "                                                      \"org.apache.hadoop.mapred.FileOutputCommitter\")\n",
    "    \n",
    "    # Defining the schema corresponding to the input data. The input data does not contain the headers\n",
    "    schema = StructType([StructField(\"sex\", StringType(), True), \n",
    "                         StructField(\"length\", DoubleType(), True),\n",
    "                         StructField(\"diameter\", DoubleType(), True),\n",
    "                         StructField(\"height\", DoubleType(), True),\n",
    "                         StructField(\"whole_weight\", DoubleType(), True),\n",
    "                         StructField(\"shucked_weight\", DoubleType(), True),\n",
    "                         StructField(\"viscera_weight\", DoubleType(), True), \n",
    "                         StructField(\"shell_weight\", DoubleType(), True), \n",
    "                         StructField(\"rings\", DoubleType(), True)])\n",
    "\n",
    "    # Downloading the data from S3 into a Dataframe\n",
    "    total_df = spark.read.csv(('s3a://' + os.path.join(args['s3_input_bucket'], args['s3_input_key_prefix'],\n",
    "                                                   'abalone.csv')), header=False, schema=schema)\n",
    "\n",
    "    #StringIndexer on the sex column which has categorical value\n",
    "    sex_indexer = StringIndexer(inputCol=\"sex\", outputCol=\"indexed_sex\")\n",
    "    \n",
    "    #one-hot-encoding is being performed on the string-indexed sex column (indexed_sex)\n",
    "    sex_encoder = OneHotEncoder(inputCol=\"indexed_sex\", outputCol=\"sex_vec\")\n",
    "\n",
    "    #vector-assembler will bring all the features to a 1D vector for us to save easily into CSV format\n",
    "    assembler = VectorAssembler(inputCols=[\"sex_vec\", \n",
    "                                           \"length\", \n",
    "                                           \"diameter\", \n",
    "                                           \"height\", \n",
    "                                           \"whole_weight\", \n",
    "                                           \"shucked_weight\", \n",
    "                                           \"viscera_weight\", \n",
    "                                           \"shell_weight\"], \n",
    "                                outputCol=\"features\")\n",
    "    \n",
    "    # The pipeline comprises of the steps added above\n",
    "    pipeline = Pipeline(stages=[sex_indexer, sex_encoder, assembler])\n",
    "    \n",
    "    # This step trains the feature transformers\n",
    "    model = pipeline.fit(total_df)\n",
    "    \n",
    "    # This step transforms the dataset with information obtained from the previous fit\n",
    "    transformed_total_df = model.transform(total_df)\n",
    "    \n",
    "    # Split the overall dataset into 80-20 training and validation\n",
    "    (train_df, validation_df) = transformed_total_df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # Convert the train dataframe to RDD to save in CSV format and upload to S3\n",
    "    train_rdd = train_df.rdd.map(lambda x: (x.rings, x.features))\n",
    "    train_lines = train_rdd.map(csv_line)\n",
    "    train_lines.saveAsTextFile('s3a://' + os.path.join(args['s3_output_bucket'], args['s3_output_key_prefix'], 'train'))\n",
    "    \n",
    "    # Convert the validation dataframe to RDD to save in CSV format and upload to S3\n",
    "    validation_rdd = validation_df.rdd.map(lambda x: (x.rings, x.features))\n",
    "    validation_lines = validation_rdd.map(csv_line)\n",
    "    validation_lines.saveAsTextFile('s3a://' + os.path.join(args['s3_output_bucket'], args['s3_output_key_prefix'], 'validation'))\n",
    "    \n",
    "    # Serialize and store the model via MLeap  \n",
    "    SimpleSparkSerializer().serializeToBundle(model, \"jar:file:/opt/ml/model.zip\", validation_df)    \n",
    "    # Unzip the model as SageMaker expects a .tar.gz file but MLeap produces a .zip file\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(\"/opt/ml/model.zip\") as zf:\n",
    "        zf.extractall(\"/opt/ml/model\")\n",
    "\n",
    "    # Writw back the content as a .tar.gz file\n",
    "    import tarfile\n",
    "    with tarfile.open(\"/opt/ml/model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(\"/opt/ml/model/bundle.json\", arcname='bundle.json')\n",
    "        tar.add(\"/opt/ml/model/root\", arcname='root')\n",
    "    \n",
    "    # Upload the model in tar.gz format to S3 so that it can be used with SageMaker for inference later\n",
    "    s3 = boto3.resource('s3') \n",
    "    file_name = os.path.join(args['s3_mleap_model_prefix'], 'model.tar.gz')\n",
    "    s3.Bucket(args['s3_model_bucket']).upload_file('/opt/ml/model.tar.gz', file_name)    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./preprocess.py to s3://ml-lab-mggaska/sparkdemo/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp preprocess.py s3://ml-lab-mggaska/sparkdemo/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  spark-preprocessor-2020-08-19-13-27-41-130\n",
      "Inputs:  [{'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-452432741922/spark-preprocessor-2020-08-19-13-27-41-130/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  []\n",
      ".......................\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,065 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.126.24\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/had\u001b[0m\n",
      "\u001b[34moop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_265\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,074 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,078 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-1a15a03e-5bfa-411b-876d-9c47122ec1ea\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,541 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,553 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,554 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,557 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,561 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,561 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,561 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,561 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,597 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,610 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,612 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,617 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,617 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Aug 19 13:31:17\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,618 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,618 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,620 INFO util.GSet: 2.0% max memory 6.7 GB = 136.2 MB\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,620 INFO util.GSet: capacity      = 2^24 = 16777216 entries\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,674 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,679 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,680 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,712 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,712 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,712 INFO util.GSet: 1.0% max memory 6.7 GB = 68.1 MB\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,712 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,729 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,729 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,729 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,730 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,734 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,738 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,738 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,738 INFO util.GSet: 0.25% max memory 6.7 GB = 17.0 MB\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,738 INFO util.GSet: capacity      = 2^21 = 2097152 entries\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,745 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,745 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,745 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,749 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,749 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,751 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,751 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,751 INFO util.GSet: 0.029999999329447746% max memory 6.7 GB = 2.0 MB\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,751 INFO util.GSet: capacity      = 2^18 = 262144 entries\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,772 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1303005269-10.0.126.24-1597843877767\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,785 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,797 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,877 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,888 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:17,892 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.126.24\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[35mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[35mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[35mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34mStarting namenodes on [algo-1]\u001b[0m\n",
      "\u001b[34malgo-1: /usr/hadoop-3.0.0/bin/../libexec/hadoop-functions.sh: line 981: ssh: command not found\u001b[0m\n",
      "\u001b[34mStarting datanodes\u001b[0m\n",
      "\u001b[34mlocalhost: /usr/hadoop-3.0.0/bin/../libexec/hadoop-functions.sh: line 981: ssh: command not found\u001b[0m\n",
      "\u001b[35mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[35mWARNING: Use of this script to start YARN daemons is deprecated.\u001b[0m\n",
      "\u001b[35mWARNING: Attempting to execute replacement \"yarn --daemon start\" instead.\u001b[0m\n",
      "\u001b[35mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[35mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34mStarting secondary namenodes [ip-10-0-126-24.ec2.internal]\u001b[0m\n",
      "\u001b[34mip-10-0-126-24.ec2.internal: /usr/hadoop-3.0.0/bin/../libexec/hadoop-functions.sh: line 981: ssh: command not found\u001b[0m\n",
      "\u001b[34mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mStarting resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mStarting nodemanagers\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mlocalhost: /usr/hadoop-3.0.0/bin/../libexec/hadoop-functions.sh: line 981: ssh: command not found\u001b[0m\n",
      "\u001b[34mIvy Default Cache set to: /root/.ivy2/cache\u001b[0m\n",
      "\u001b[34mThe jars for the packages stored in: /root/.ivy2/jars\u001b[0m\n",
      "\u001b[34m:: loading settings :: url = jar:file:/usr/spark-2.2.0/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\u001b[0m\n",
      "\u001b[34mml.combust.mleap#mleap-spark_2.11 added as a dependency\u001b[0m\n",
      "\u001b[34m:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0\u001b[0m\n",
      "\u001b[34m#011confs: [default]\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-spark_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-spark-base_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-runtime_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-core_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-base_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.mleap#mleap-tensor_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found io.spray#spray-json_2.11;1.3.2 in central\u001b[0m\n",
      "\u001b[34m#011found org.apache.spark#spark-mllib-local_2.11;2.2.0 in central\u001b[0m\n",
      "\u001b[34m#011found org.scalanlp#breeze_2.11;0.13.1 in central\u001b[0m\n",
      "\u001b[34m#011found org.scalanlp#breeze-macros_2.11;0.13.1 in central\u001b[0m\n",
      "\u001b[34m#011found org.scala-lang#scala-reflect;2.11.8 in central\u001b[0m\n",
      "\u001b[34m#011found com.github.fommil.netlib#core;1.1.2 in central\u001b[0m\n",
      "\u001b[34m#011found net.sourceforge.f2j#arpack_combined_all;0.1 in central\u001b[0m\n",
      "\u001b[34m#011found net.sf.opencsv#opencsv;2.3 in central\u001b[0m\n",
      "\u001b[34m#011found com.github.rwl#jtransforms;2.4.0 in central\u001b[0m\n",
      "\u001b[34m#011found junit#junit;4.12 in central\u001b[0m\n",
      "\u001b[34m#011found org.hamcrest#hamcrest-core;1.3 in central\u001b[0m\n",
      "\u001b[34m#011found org.spire-math#spire_2.11;0.13.0 in central\u001b[0m\n",
      "\u001b[34m#011found org.spire-math#spire-macros_2.11;0.13.0 in central\u001b[0m\n",
      "\u001b[34m#011found org.typelevel#machinist_2.11;0.6.1 in central\u001b[0m\n",
      "\u001b[34m#011found com.chuusai#shapeless_2.11;2.3.2 in central\u001b[0m\n",
      "\u001b[34m#011found org.typelevel#macro-compat_2.11;1.1.1 in central\u001b[0m\n",
      "\u001b[34m#011found org.slf4j#slf4j-api;1.7.16 in central\u001b[0m\n",
      "\u001b[34m#011found org.apache.commons#commons-math3;3.4.1 in central\u001b[0m\n",
      "\u001b[34m#011found org.apache.spark#spark-tags_2.11;2.2.0 in central\u001b[0m\n",
      "\u001b[34m#011found org.spark-project.spark#unused;1.0.0 in central\u001b[0m\n",
      "\u001b[34m#011found ml.combust.bundle#bundle-ml_2.11;0.8.1 in central\u001b[0m\n",
      "\u001b[34m#011found com.trueaccord.scalapb#scalapb-runtime_2.11;0.6.0 in central\u001b[0m\n",
      "\u001b[34m#011found com.trueaccord.lenses#lenses_2.11;0.4.12 in central\u001b[0m\n",
      "\u001b[34m#011found com.lihaoyi#fastparse_2.11;0.4.2 in central\u001b[0m\n",
      "\u001b[34m#011found com.lihaoyi#fastparse-utils_2.11;0.4.2 in central\u001b[0m\n",
      "\u001b[34m#011found com.lihaoyi#sourcecode_2.11;0.1.3 in central\u001b[0m\n",
      "\u001b[34m#011found com.google.protobuf#protobuf-java;3.3.1 in central\u001b[0m\n",
      "\u001b[34m#011found com.jsuereth#scala-arm_2.11;2.0 in central\u001b[0m\n",
      "\u001b[34m#011found com.typesafe#config;1.3.0 in central\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-spark_2.11/0.8.1/mleap-spark_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-spark_2.11;0.8.1!mleap-spark_2.11.jar (21ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-spark-base_2.11/0.8.1/mleap-spark-base_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-spark-base_2.11;0.8.1!mleap-spark-base_2.11.jar (7ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-runtime_2.11/0.8.1/mleap-runtime_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-runtime_2.11;0.8.1!mleap-runtime_2.11.jar (30ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-core_2.11/0.8.1/mleap-core_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-core_2.11;0.8.1!mleap-core_2.11.jar (22ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/bundle/bundle-ml_2.11/0.8.1/bundle-ml_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.bundle#bundle-ml_2.11;0.8.1!bundle-ml_2.11.jar (43ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.scala-lang#scala-reflect;2.11.8!scala-reflect.jar (95ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-base_2.11/0.8.1/mleap-base_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-base_2.11;0.8.1!mleap-base_2.11.jar (2ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/ml/combust/mleap/mleap-tensor_2.11/0.8.1/mleap-tensor_2.11-0.8.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] ml.combust.mleap#mleap-tensor_2.11;0.8.1!mleap-tensor_2.11.jar (5ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/apache/spark/spark-mllib-local_2.11/2.2.0/spark-mllib-local_2.11-2.2.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.apache.spark#spark-mllib-local_2.11;2.2.0!spark-mllib-local_2.11.jar (11ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.github.rwl#jtransforms;2.4.0!jtransforms.jar (30ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/io/spray/spray-json_2.11/1.3.2/spray-json_2.11-1.3.2.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] io.spray#spray-json_2.11;1.3.2!spray-json_2.11.jar(bundle) (13ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/scalanlp/breeze_2.11/0.13.1/breeze_2.11-0.13.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.scalanlp#breeze_2.11;0.13.1!breeze_2.11.jar (176ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.apache.commons#commons-math3;3.4.1!commons-math3.jar (16ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/apache/spark/spark-tags_2.11/2.2.0/spark-tags_2.11-2.2.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.apache.spark#spark-tags_2.11;2.2.0!spark-tags_2.11.jar (2ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/scalanlp/breeze-macros_2.11/0.13.1/breeze-macros_2.11-0.13.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.scalanlp#breeze-macros_2.11;0.13.1!breeze-macros_2.11.jar (5ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.github.fommil.netlib#core;1.1.2!core.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1-javadoc.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] net.sourceforge.f2j#arpack_combined_all;0.1!arpack_combined_all.jar (49ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] net.sf.opencsv#opencsv;2.3!opencsv.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/spire-math/spire_2.11/0.13.0/spire_2.11-0.13.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.spire-math#spire_2.11;0.13.0!spire_2.11.jar (71ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/chuusai/shapeless_2.11/2.3.2/shapeless_2.11-2.3.2.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.chuusai#shapeless_2.11;2.3.2!shapeless_2.11.jar(bundle) (30ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.16!slf4j-api.jar (6ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/junit/junit/4.12/junit-4.12.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] junit#junit;4.12!junit.jar (5ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.3!hamcrest-core.jar (6ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/spire-math/spire-macros_2.11/0.13.0/spire-macros_2.11-0.13.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.spire-math#spire-macros_2.11;0.13.0!spire-macros_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.1/machinist_2.11-0.6.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.typelevel#machinist_2.11;0.6.1!machinist_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] org.typelevel#macro-compat_2.11;1.1.1!macro-compat_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/trueaccord/scalapb/scalapb-runtime_2.11/0.6.0/scalapb-runtime_2.11-0.6.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.trueaccord.scalapb#scalapb-runtime_2.11;0.6.0!scalapb-runtime_2.11.jar (26ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/jsuereth/scala-arm_2.11/2.0/scala-arm_2.11-2.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.jsuereth#scala-arm_2.11;2.0!scala-arm_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/typesafe/config/1.3.0/config-1.3.0.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.typesafe#config;1.3.0!config.jar(bundle) (5ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/trueaccord/lenses/lenses_2.11/0.4.12/lenses_2.11-0.4.12.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.trueaccord.lenses#lenses_2.11;0.4.12!lenses_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/lihaoyi/fastparse_2.11/0.4.2/fastparse_2.11-0.4.2.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.lihaoyi#fastparse_2.11;0.4.2!fastparse_2.11.jar (5ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.3.1/protobuf-java-3.3.1.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.3.1!protobuf-java.jar(bundle) (11ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/lihaoyi/fastparse-utils_2.11/0.4.2/fastparse-utils_2.11-0.4.2.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.lihaoyi#fastparse-utils_2.11;0.4.2!fastparse-utils_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34mdownloading https://repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.11/0.1.3/sourcecode_2.11-0.1.3.jar ...\u001b[0m\n",
      "\u001b[34m#011[SUCCESSFUL ] com.lihaoyi#sourcecode_2.11;0.1.3!sourcecode_2.11.jar (3ms)\u001b[0m\n",
      "\u001b[34m:: resolution report :: resolve 3330ms :: artifacts dl 739ms\u001b[0m\n",
      "\u001b[34m#011:: modules in use:\u001b[0m\n",
      "\u001b[34m#011com.chuusai#shapeless_2.11;2.3.2 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.github.fommil.netlib#core;1.1.2 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.github.rwl#jtransforms;2.4.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.google.protobuf#protobuf-java;3.3.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.jsuereth#scala-arm_2.11;2.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.lihaoyi#fastparse-utils_2.11;0.4.2 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.lihaoyi#fastparse_2.11;0.4.2 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.lihaoyi#sourcecode_2.11;0.1.3 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.trueaccord.lenses#lenses_2.11;0.4.12 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.trueaccord.scalapb#scalapb-runtime_2.11;0.6.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011com.typesafe#config;1.3.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011io.spray#spray-json_2.11;1.3.2 from central in [default]\u001b[0m\n",
      "\u001b[34m#011junit#junit;4.12 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.bundle#bundle-ml_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-base_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-core_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-runtime_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-spark-base_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-spark_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011ml.combust.mleap#mleap-tensor_2.11;0.8.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011net.sf.opencsv#opencsv;2.3 from central in [default]\u001b[0m\n",
      "\u001b[34m#011net.sourceforge.f2j#arpack_combined_all;0.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.apache.commons#commons-math3;3.4.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.apache.spark#spark-mllib-local_2.11;2.2.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.apache.spark#spark-tags_2.11;2.2.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.hamcrest#hamcrest-core;1.3 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.scala-lang#scala-reflect;2.11.8 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.scalanlp#breeze-macros_2.11;0.13.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.scalanlp#breeze_2.11;0.13.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.slf4j#slf4j-api;1.7.16 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.spark-project.spark#unused;1.0.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.spire-math#spire-macros_2.11;0.13.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.spire-math#spire_2.11;0.13.0 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.typelevel#machinist_2.11;0.6.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011org.typelevel#macro-compat_2.11;1.1.1 from central in [default]\u001b[0m\n",
      "\u001b[34m#011---------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m#011|                  |            modules            ||   artifacts   |\u001b[0m\n",
      "\u001b[34m#011|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\u001b[0m\n",
      "\u001b[34m#011---------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m#011|      default     |   35  |   35  |   35  |   0   ||   35  |   35  |\u001b[0m\n",
      "\u001b[34m#011---------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m:: retrieving :: org.apache.spark#spark-submit-parent\u001b[0m\n",
      "\u001b[34m#011confs: [default]\u001b[0m\n",
      "\u001b[34m#01135 artifacts copied, 0 already retrieved (52376kB/60ms)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,192 INFO spark.SparkContext: Running Spark version 2.2.0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,348 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,444 INFO spark.SparkContext: Submitted application: PySparkAbalone\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,459 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,459 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,460 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,460 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,461 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,658 INFO util.Utils: Successfully started service 'sparkDriver' on port 45465.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,673 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,688 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,691 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,692 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,698 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1b9cf06d-6092-4c2f-bcf8-296d635bbb16\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,716 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,797 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,859 INFO util.log: Logging initialized @6347ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,908 INFO server.Server: jetty-9.3.z-SNAPSHOT\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,921 INFO server.Server: Started @6410ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,938 INFO server.AbstractConnector: Started ServerConnector@7f38f94f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,938 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,961 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@691c9520{/jobs,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,961 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@46d8933e{/jobs/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,962 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3385d647{/jobs/job,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,962 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@700617a4{/jobs/job/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,963 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5132dc69{/stages,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,963 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36cc3dc9{/stages/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,964 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a7dede5{/stages/stage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,965 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13f97d76{/stages/stage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,965 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6efd56fe{/stages/pool,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,966 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@456edf45{/stages/pool/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,966 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4012fb9e{/storage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,967 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e36f295{/storage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,967 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3dad722a{/storage/rdd,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,968 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35e24764{/storage/rdd/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,968 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c245192{/environment,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,969 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@ad3a14a{/environment/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,969 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c35591a{/executors,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,970 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e447990{/executors/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,971 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63176591{/executors/threadDump,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,971 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5b3d500{/executors/threadDump/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,977 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7874c7a2{/static,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,978 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@534d056d{/,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,979 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68c76bdf{/api,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,980 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@668c6daf{/jobs/job/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,981 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65717b1c{/stages/stage/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:35,982 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.126.24:4040\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:36,859 INFO client.RMProxy: Connecting to ResourceManager at /10.0.126.24:8032\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,113 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,172 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,172 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,179 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (31706 MB per container)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,179 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,179 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,182 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:37,188 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-08-19 13:31:38,041 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:38,725 INFO yarn.Client: Uploading resource file:/tmp/spark-f4563d98-db77-48d6-a62f-10fe21f8fbb7/__spark_libs__8511590895264708562.zip -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/__spark_libs__8511590895264708562.zip\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:40,228 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-spark_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-spark_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:40,659 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-spark-base_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-spark-base_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,084 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-runtime_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-runtime_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,111 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-core_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-core_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,134 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.bundle_bundle-ml_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.bundle_bundle-ml_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,160 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.scala-lang_scala-reflect-2.11.8.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.scala-lang_scala-reflect-2.11.8.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,200 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-base_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-base_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,220 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-tensor_2.11-0.8.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/ml.combust.mleap_mleap-tensor_2.11-0.8.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,249 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.apache.spark_spark-mllib-local_2.11-2.2.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.apache.spark_spark-mllib-local_2.11-2.2.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,273 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.github.rwl_jtransforms-2.4.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,296 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/io.spray_spray-json_2.11-1.3.2.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/io.spray_spray-json_2.11-1.3.2.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,319 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.scalanlp_breeze_2.11-0.13.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.scalanlp_breeze_2.11-0.13.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,382 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.apache.commons_commons-math3-3.4.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.apache.commons_commons-math3-3.4.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,408 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.apache.spark_spark-tags_2.11-2.2.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.apache.spark_spark-tags_2.11-2.2.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,430 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.spark-project.spark_unused-1.0.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,454 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.scalanlp_breeze-macros_2.11-0.13.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.scalanlp_breeze-macros_2.11-0.13.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,503 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.github.fommil.netlib_core-1.1.2.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,524 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/net.sourceforge.f2j_arpack_combined_all-0.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,557 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/net.sf.opencsv_opencsv-2.3.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,578 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.spire-math_spire_2.11-0.13.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.spire-math_spire_2.11-0.13.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,629 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.chuusai_shapeless_2.11-2.3.2.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.chuusai_shapeless_2.11-2.3.2.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,667 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.slf4j_slf4j-api-1.7.16.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,800 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/junit_junit-4.12.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/junit_junit-4.12.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:41,822 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.hamcrest_hamcrest-core-1.3.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.hamcrest_hamcrest-core-1.3.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,254 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.spire-math_spire-macros_2.11-0.13.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.spire-math_spire-macros_2.11-0.13.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,273 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.typelevel_machinist_2.11-0.6.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.typelevel_machinist_2.11-0.6.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,291 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/org.typelevel_macro-compat_2.11-1.1.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/org.typelevel_macro-compat_2.11-1.1.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,309 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.trueaccord.scalapb_scalapb-runtime_2.11-0.6.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.trueaccord.scalapb_scalapb-runtime_2.11-0.6.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,344 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.jsuereth_scala-arm_2.11-2.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.jsuereth_scala-arm_2.11-2.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,363 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.typesafe_config-1.3.0.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.typesafe_config-1.3.0.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,384 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.trueaccord.lenses_lenses_2.11-0.4.12.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.trueaccord.lenses_lenses_2.11-0.4.12.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,402 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.lihaoyi_fastparse_2.11-0.4.2.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.lihaoyi_fastparse_2.11-0.4.2.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,418 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.google.protobuf_protobuf-java-3.3.1.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.google.protobuf_protobuf-java-3.3.1.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,436 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.lihaoyi_fastparse-utils_2.11-0.4.2.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.lihaoyi_fastparse-utils_2.11-0.4.2.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,454 INFO yarn.Client: Uploading resource file:/root/.ivy2/jars/com.lihaoyi_sourcecode_2.11-0.1.3.jar -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/com.lihaoyi_sourcecode_2.11-0.1.3.jar\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,482 INFO yarn.Client: Uploading resource file:/usr/spark-2.2.0/python/lib/pyspark.zip -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/pyspark.zip\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,501 INFO yarn.Client: Uploading resource file:/usr/spark-2.2.0/python/lib/py4j-0.10.4-src.zip -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/py4j-0.10.4-src.zip\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-spark_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-spark-base_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-runtime_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-core_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.bundle_bundle-ml_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.scala-lang_scala-reflect-2.11.8.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-base_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/ml.combust.mleap_mleap-tensor_2.11-0.8.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.apache.spark_spark-mllib-local_2.11-2.2.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/io.spray_spray-json_2.11-1.3.2.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.scalanlp_breeze_2.11-0.13.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.apache.commons_commons-math3-3.4.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.apache.spark_spark-tags_2.11-2.2.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.scalanlp_breeze-macros_2.11-0.13.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.spire-math_spire_2.11-0.13.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.chuusai_shapeless_2.11-2.3.2.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/junit_junit-4.12.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,519 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.hamcrest_hamcrest-core-1.3.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.spire-math_spire-macros_2.11-0.13.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.typelevel_machinist_2.11-0.6.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/org.typelevel_macro-compat_2.11-1.1.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.trueaccord.scalapb_scalapb-runtime_2.11-0.6.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.jsuereth_scala-arm_2.11-2.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.typesafe_config-1.3.0.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.trueaccord.lenses_lenses_2.11-0.4.12.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.lihaoyi_fastparse_2.11-0.4.2.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.google.protobuf_protobuf-java-3.3.1.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.lihaoyi_fastparse-utils_2.11-0.4.2.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,520 WARN yarn.Client: Same path resource file:/root/.ivy2/jars/com.lihaoyi_sourcecode_2.11-0.1.3.jar added multiple times to distributed cache.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,534 INFO yarn.Client: Uploading resource file:/tmp/spark-f4563d98-db77-48d6-a62f-10fe21f8fbb7/__spark_conf__8205269724902438924.zip -> hdfs://10.0.126.24/user/root/.sparkStaging/application_1597843887193_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,568 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,568 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,568 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,568 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,568 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,573 INFO yarn.Client: Submitting application application_1597843887193_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,768 INFO impl.YarnClientImpl: Submitted application application_1597843887193_0001\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:42,770 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1597843887193_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:43,775 INFO yarn.Client: Application report for application_1597843887193_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:43,778 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1597843902674\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1597843887193_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:44,780 INFO yarn.Client: Application report for application_1597843887193_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:45,783 INFO yarn.Client: Application report for application_1597843887193_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:46,785 INFO yarn.Client: Application report for application_1597843887193_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:47,789 INFO yarn.Client: Application report for application_1597843887193_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:47,792 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:47,796 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1597843887193_0001), /proxy/application_1597843887193_0001\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:47,798 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,791 INFO yarn.Client: Application report for application_1597843887193_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,792 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.106.237\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1597843902674\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1597843887193_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,792 INFO cluster.YarnClientSchedulerBackend: Application application_1597843887193_0001 has started running.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,827 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33621.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,828 INFO netty.NettyBlockTransferService: Server created on 10.0.126.24:33621\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,829 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,831 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.126.24, 33621, None)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,834 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.126.24:33621 with 366.3 MB RAM, BlockManagerId(driver, 10.0.126.24, 33621, None)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,837 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.126.24, 33621, None)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,837 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.126.24, 33621, None)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:48,848 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38ce52a7{/metrics/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:51,458 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.106.237:55112) with ID 1\u001b[0m\n",
      "\u001b[34m2020-08-19 13:31:51,490 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-2:45789 with 11.9 GB RAM, BlockManagerId(1, algo-2, 45789, None)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-08-19 13:32:06,174 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,338 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.2.0/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,339 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-2.2.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,343 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4a11ef03{/SQL,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,343 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f2ec360{/SQL/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,344 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@29289560{/SQL/execution,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,344 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62f10152{/SQL/execution/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,345 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@55ea50ce{/static/sql,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:06,674 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:07,588 INFO Configuration.deprecation: fs.s3a.server-side-encryption-key is deprecated. Instead, use fs.s3a.server-side-encryption.key\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,191 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,193 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, sex#0)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,194 INFO datasources.FileSourceStrategy: Output Data Schema: struct<sex: string>\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,201 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,560 INFO codegen.CodeGenerator: Code generated in 152.908001 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,614 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 444.5 KB, free 365.9 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,654 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.5 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,656 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.126.24:33621 (size: 41.5 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,660 INFO spark.SparkContext: Created broadcast 0 from rdd at StringIndexer.scala:111\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,683 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,830 INFO spark.SparkContext: Starting job: countByValue at StringIndexer.scala:113\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,956 INFO scheduler.DAGScheduler: Registering RDD 6 (countByValue at StringIndexer.scala:113)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,958 INFO scheduler.DAGScheduler: Got job 0 (countByValue at StringIndexer.scala:113) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,958 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (countByValue at StringIndexer.scala:113)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,959 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,960 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:08,964 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at countByValue at StringIndexer.scala:113), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,023 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.5 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,025 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.5 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,026 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.126.24:33621 (size: 8.5 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,027 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,038 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,039 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,062 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, algo-2, executor 1, partition 0, PROCESS_LOCAL, 5357 bytes)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:09,283 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-2:45789 (size: 8.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:10,316 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-2:45789 (size: 41.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,888 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2833 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,890 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,896 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (countByValue at StringIndexer.scala:113) finished in 2.843 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,897 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,897 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,898 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,898 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,902 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[7] at countByValue at StringIndexer.scala:113), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,911 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,913 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1963.0 B, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,914 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.126.24:33621 (size: 1963.0 B, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,914 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,916 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[7] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,916 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,921 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, algo-2, executor 1, partition 0, NODE_LOCAL, 4632 bytes)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,953 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-2:45789 (size: 1963.0 B, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,968 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.106.237:55112\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:11,971 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 137 bytes\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,009 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 90 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,009 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,010 INFO scheduler.DAGScheduler: ResultStage 1 (countByValue at StringIndexer.scala:113) finished in 0.091 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,015 INFO scheduler.DAGScheduler: Job 0 finished: countByValue at StringIndexer.scala:113, took 3.185031 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,495 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,495 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,496 INFO datasources.FileSourceStrategy: Output Data Schema: struct<sex: string, length: double, diameter: double, height: double, whole_weight: double ... 7 more fields>\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,496 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,704 INFO codegen.CodeGenerator: Code generated in 173.005044 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,730 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 444.5 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,748 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 41.5 KB, free 365.3 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,749 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.126.24:33621 (size: 41.5 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,750 INFO spark.SparkContext: Created broadcast 3 from javaToPython at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,750 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,909 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:12,909 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,409 INFO spark.SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,410 INFO scheduler.DAGScheduler: Got job 1 (saveAsTextFile at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,410 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (saveAsTextFile at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,410 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,410 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,411 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,435 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 174.2 KB, free 365.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,438 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 64.1 KB, free 365.1 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,438 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.126.24:33621 (size: 64.1 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,439 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,439 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,440 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,441 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, algo-2, executor 1, partition 0, PROCESS_LOCAL, 5368 bytes)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:13,451 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-2:45789 (size: 64.1 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:14,251 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-2:45789 (size: 41.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:16,878 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 3438 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:16,878 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:16,881 INFO scheduler.DAGScheduler: ResultStage 2 (saveAsTextFile at NativeMethodAccessorImpl.java:0) finished in 3.441 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:16,881 INFO scheduler.DAGScheduler: Job 1 finished: saveAsTextFile at NativeMethodAccessorImpl.java:0, took 3.471847 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,536 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.126.24:33621 in memory (size: 8.5 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,545 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-2:45789 in memory (size: 8.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,552 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.126.24:33621 in memory (size: 1963.0 B, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,554 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on algo-2:45789 in memory (size: 1963.0 B, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,557 INFO spark.ContextCleaner: Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,557 INFO spark.ContextCleaner: Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,560 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.126.24:33621 in memory (size: 41.5 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,561 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-2:45789 in memory (size: 41.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,566 INFO spark.ContextCleaner: Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,566 INFO spark.ContextCleaner: Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,566 INFO spark.ContextCleaner: Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,570 INFO spark.ContextCleaner: Cleaned shuffle 0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,570 INFO spark.ContextCleaner: Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,571 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.126.24:33621 in memory (size: 64.1 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,573 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-2:45789 in memory (size: 64.1 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,734 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,734 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,734 INFO datasources.FileSourceStrategy: Output Data Schema: struct<sex: string, length: double, diameter: double, height: double, whole_weight: double ... 7 more fields>\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,735 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,819 INFO codegen.CodeGenerator: Code generated in 70.890345 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,838 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 444.5 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,854 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 41.5 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,855 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.126.24:33621 (size: 41.5 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,856 INFO spark.SparkContext: Created broadcast 5 from javaToPython at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,857 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,950 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:17,950 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,252 INFO spark.SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,253 INFO scheduler.DAGScheduler: Got job 2 (saveAsTextFile at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,253 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,253 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,253 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,253 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,267 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 174.2 KB, free 365.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,269 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 64.0 KB, free 365.1 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,270 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.126.24:33621 (size: 64.0 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,270 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,271 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,271 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,272 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, algo-2, executor 1, partition 0, PROCESS_LOCAL, 5368 bytes)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,283 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-2:45789 (size: 64.0 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:18,392 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-2:45789 (size: 41.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:20,115 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1843 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:20,116 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:20,117 INFO scheduler.DAGScheduler: ResultStage 3 (saveAsTextFile at NativeMethodAccessorImpl.java:0) finished in 1.843 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:20,117 INFO scheduler.DAGScheduler: Job 2 finished: saveAsTextFile at NativeMethodAccessorImpl.java:0, took 1.865326 s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-08-19 13:32:20,999 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:20,999 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,000 INFO datasources.FileSourceStrategy: Output Data Schema: struct<sex: string, length: double, diameter: double, height: double, whole_weight: double ... 7 more fields>\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,000 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,092 INFO codegen.CodeGenerator: Code generated in 50.560046 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,110 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 444.5 KB, free 364.7 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,124 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 41.5 KB, free 364.6 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,125 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.126.24:33621 (size: 41.5 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,126 INFO spark.SparkContext: Created broadcast 7 from sparkToMleapDataShape at VectorAssemblerOp.scala:26\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,128 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,141 INFO spark.SparkContext: Starting job: sparkToMleapDataShape at VectorAssemblerOp.scala:26\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,142 INFO scheduler.DAGScheduler: Got job 3 (sparkToMleapDataShape at VectorAssemblerOp.scala:26) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,142 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (sparkToMleapDataShape at VectorAssemblerOp.scala:26)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,142 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,142 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,143 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at sparkToMleapDataShape at VectorAssemblerOp.scala:26), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,147 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 56.4 KB, free 364.6 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,148 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.7 KB, free 364.6 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,149 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.126.24:33621 (size: 20.7 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,149 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,150 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at sparkToMleapDataShape at VectorAssemblerOp.scala:26) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,150 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,151 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, algo-2, executor 1, partition 0, PROCESS_LOCAL, 5368 bytes)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,163 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-2:45789 (size: 20.7 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,234 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-2:45789 (size: 41.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,369 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 218 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,370 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,371 INFO scheduler.DAGScheduler: ResultStage 4 (sparkToMleapDataShape at VectorAssemblerOp.scala:26) finished in 0.218 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,373 INFO scheduler.DAGScheduler: Job 3 finished: sparkToMleapDataShape at VectorAssemblerOp.scala:26, took 0.231111 s\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,397 INFO codegen.CodeGenerator: Code generated in 10.657948 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,683 INFO spark.SparkContext: Invoking stop() from shutdown hook\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,687 INFO server.AbstractConnector: Stopped Spark@7f38f94f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,689 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.126.24:4040\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,694 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,704 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,704 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,707 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,709 INFO cluster.YarnClientSchedulerBackend: Stopped\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,713 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,717 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,718 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,718 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,720 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,731 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,731 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,732 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f4563d98-db77-48d6-a62f-10fe21f8fbb7\u001b[0m\n",
      "\u001b[34m2020-08-19 13:32:21,733 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f4563d98-db77-48d6-a62f-10fe21f8fbb7/pyspark-621494b0-415b-4a56-98e9-a0b96ee7be34\u001b[0m\n",
      "\u001b[35m2020-08-19 13:32:23\u001b[0m\n",
      "\u001b[35mFinished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[35mReceived end of job signal, exiting...\u001b[0m\n",
      "\u001b[34mFinished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "spark_processor = ScriptProcessor(base_job_name='spark-preprocessor',\n",
    "                                  image_uri=spark_repository_uri,\n",
    "                                  command=['/opt/program/submit'],\n",
    "                                  role=role,\n",
    "                                  instance_count=2,\n",
    "                                  instance_type='ml.r5.xlarge',\n",
    "                                  max_runtime_in_seconds=800,\n",
    "                                  env={'mode': 'python'})\n",
    "\n",
    "spark_processor.run(code='preprocess.py',\n",
    "                    arguments=['s3_input_bucket', bucket,\n",
    "                               's3_input_key_prefix', input_prefix,\n",
    "                               's3_output_bucket', bucket,\n",
    "                               's3_output_key_prefix', input_preprocessed_prefix,\n",
    "                               's3_model_bucket', bucket,\n",
    "                               's3_mleap_model_prefix', mleap_model_prefix],\n",
    "                    logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows from s3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/2020-08-18-22-44-22/input/preprocessed/abalone/train/\n",
      "5.0,0.0,0.0,0.275,0.195,0.07,0.08,0.031,0.0215,0.025\n",
      "6.0,0.0,0.0,0.29,0.21,0.075,0.275,0.113,0.0675,0.035\n",
      "7.0,0.0,0.0,0.305,0.225,0.07,0.1485,0.0585,0.0335,0.045\n",
      "9.0,0.0,0.0,0.33,0.26,0.08,0.2,0.0625,0.05,0.07\n",
      "6.0,0.0,0.0,0.335,0.22,0.07,0.17,0.076,0.0365,0.05\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 rows from s3://{}/{}/train/'.format(bucket, input_preprocessed_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$input_preprocessed_prefix/train/part-00000 - | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sagemaker_session.boto_region_name, 'xgboost', repo_version=\"0.90-1\")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::452432741922:role/workshop-role'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "s3_train_data = 's3://{}/{}/{}'.format(bucket, input_preprocessed_prefix, 'train/part')\n",
    "s3_validation_data = 's3://{}/{}/{}'.format(bucket, input_preprocessed_prefix, 'validation/part')\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model')\n",
    "\n",
    "xgb_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m4.xlarge',\n",
    "                                          train_volume_size = 20,\n",
    "                                          train_max_run = 3600,\n",
    "                                          input_mode= 'File',\n",
    "                                          output_path=s3_output_location,\n",
    "                                          sagemaker_session=sagemaker_session)\n",
    "\n",
    "xgb_model.set_hyperparameters(objective = \"reg:linear\",\n",
    "                              eta = .2,\n",
    "                              gamma = 4,\n",
    "                              max_depth = 5,\n",
    "                              num_round = 10,\n",
    "                              subsample = 0.7,\n",
    "                              silent = 0,\n",
    "                              min_child_weight = 6)\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/csv', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/csv', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model.Model at 0x7fb5ed51f940>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/2020-08-18-22-44-22/input/preprocessed/abalone/train/part'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/2020-08-18-22-44-22/input/preprocessed/abalone/train/part',\n",
       "   'S3DataDistributionType': 'FullyReplicated'}},\n",
       " 'ContentType': 'text/csv'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-19 14:03:08 Starting - Starting the training job...\n",
      "2020-08-19 14:03:14 Starting - Launching requested ML instances.........\n",
      "2020-08-19 14:04:56 Starting - Preparing the instances for training......\n",
      "2020-08-19 14:06:09 Downloading - Downloading input data\n",
      "2020-08-19 14:06:09 Training - Downloading the training image.....\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:06:44] 3339x9 matrix with 30051 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:06:44] 838x9 matrix with 7542 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 3339 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 838 rows\u001b[0m\n",
      "\u001b[34m[14:06:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:8.04451#011validation-rmse:8.35708\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:6.57821#011validation-rmse:6.8982\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:5.42652#011validation-rmse:5.75848\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:4.5235#011validation-rmse:4.87118\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:3.82644#011validation-rmse:4.19362\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:3.28847#011validation-rmse:3.67908\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.88632#011validation-rmse:3.29715\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.59587#011validation-rmse:3.02758\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:2.38279#011validation-rmse:2.82147\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:2.23912#011validation-rmse:2.69186\u001b[0m\n",
      "\n",
      "2020-08-19 14:06:54 Uploading - Uploading generated training model\n",
      "2020-08-19 14:06:54 Completed - Training job completed\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input\": [{\"name\": \"sex\", \"type\": \"string\"}, {\"name\": \"length\", \"type\": \"double\"}, {\"name\": \"diameter\", \"type\": \"double\"}, {\"name\": \"height\", \"type\": \"double\"}, {\"name\": \"whole_weight\", \"type\": \"double\"}, {\"name\": \"shucked_weight\", \"type\": \"double\"}, {\"name\": \"viscera_weight\", \"type\": \"double\"}, {\"name\": \"shell_weight\", \"type\": \"double\"}], \"output\": {\"name\": \"features\", \"type\": \"double\", \"struct\": \"vector\"}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "schema = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"name\": \"sex\",\n",
    "            \"type\": \"string\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"length\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"diameter\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"height\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"whole_weight\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"shucked_weight\",\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"viscera_weight\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"shell_weight\",\n",
    "            \"type\": \"double\"\n",
    "        }, \n",
    "    ],\n",
    "    \"output\": \n",
    "        {\n",
    "            \"name\": \"features\",\n",
    "            \"type\": \"double\",\n",
    "            \"struct\": \"vector\"\n",
    "        }\n",
    "}\n",
    "schema_json = json.dumps(schema)\n",
    "print(schema_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/2020-08-18-22-44-22/xgboost_model/sagemaker-xgboost-2020-08-19-14-03-08-551/output/model.tar.gz'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/sagemaker/spark-preprocess-demo/2020-08-18-22-44-22/xgboost_model'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_compilation_job_config',\n",
       " '_create_sagemaker_model',\n",
       " '_enable_network_isolation',\n",
       " '_framework',\n",
       " '_get_framework_version',\n",
       " '_inferentia_image',\n",
       " '_init_sagemaker_session_if_does_not_exist',\n",
       " '_is_compiled_model',\n",
       " '_model_name',\n",
       " '_neo_image',\n",
       " '_neo_image_account',\n",
       " 'check_neo_region',\n",
       " 'compile',\n",
       " 'delete_model',\n",
       " 'deploy',\n",
       " 'enable_network_isolation',\n",
       " 'endpoint_name',\n",
       " 'env',\n",
       " 'image',\n",
       " 'model_data',\n",
       " 'model_kms_key',\n",
       " 'name',\n",
       " 'predictor_cls',\n",
       " 'prepare_container_def',\n",
       " 'role',\n",
       " 'sagemaker_session',\n",
       " 'transformer',\n",
       " 'vpc_config']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker/spark-preprocess-demo/automated-job/mleap-model'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mleap_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-452432741922'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.sparkml.model import SparkMLModel\n",
    "\n",
    "sparkml_data = 's3://{}/{}/{}'.format(bucket, mleap_model_prefix, 'model.tar.gz')\n",
    "# passing the schema defined above by using an environment variable that sagemaker-sparkml-serving understands\n",
    "sparkml_model = SparkMLModel(model_data=sparkml_data, env={'SAGEMAKER_SPARKML_SCHEMA' : schema_json})\n",
    "xgb_model = Model(model_data=xgb_model.model_data, image=training_image)\n",
    "\n",
    "model_name = 'inference-pipeline-' + timestamp_prefix\n",
    "sm_model = PipelineModel(name=model_name, role=role, models=[sparkml_model, xgb_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = 'inference-pipeline-ep-' + timestamp_prefix\n",
    "# sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "# payload = \"F,0.515,0.425,0.14,0.766,0.304,0.1725,0.255\"\n",
    "# predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker_session, serializer=csv_serializer,\n",
    "#                                 content_type=CONTENT_TYPE_CSV, accept=CONTENT_TYPE_CSV)\n",
    "# print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\"data\": [\"F\",0.515,0.425,0.14,0.766,0.304,0.1725,0.255]}\n",
    "# predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker_session, serializer=json_serializer,\n",
    "#                                 content_type=CONTENT_TYPE_JSON, accept=CONTENT_TYPE_CSV)\n",
    "\n",
    "# print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-19 15:08:31--  https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/batch_input_abalone.csv\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.218.208\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.218.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 654 [text/csv]\n",
      "Saving to: ‘batch_input_abalone.csv.1’\n",
      "\n",
      "batch_input_abalone 100%[===================>]     654  --.-KB/s    in 0s      \n",
      "\n",
      "2020-08-19 15:08:31 (19.9 MB/s) - ‘batch_input_abalone.csv.1’ saved [654/654]\n",
      "\n",
      "\n",
      "\n",
      "Showing first five lines\n",
      "\n",
      "M,0.455,0.365,0.095,0.514,0.2245,0.101,0.15\n",
      "M,0.35,0.265,0.09,0.2255,0.0995,0.0485,0.07\n",
      "F,0.53,0.42,0.135,0.677,0.2565,0.1415,0.21\n",
      "M,0.44,0.365,0.125,0.516,0.2155,0.114,0.155\n",
      "I,0.33,0.255,0.08,0.205,0.0895,0.0395,0.055\n",
      "\n",
      "\n",
      "As we can see, it is identical to the training file apart from the label being absent here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/batch_input_abalone.csv\n",
    "!printf \"\\n\\nShowing first five lines\\n\\n\"    \n",
    "!head -n 5 batch_input_abalone.csv \n",
    "!printf \"\\n\\nAs we can see, it is identical to the training file apart from the label being absent here.\\n\\n\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " = sagemaker_session.upload_data(path='batch_input_abalone.csv', bucket=bucket, key_prefix='batch')batch_input_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::452432741922:role/workshop-role'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = sm_model.transformer(1,'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................\u001b[34m  .   ____          _            __ _ _\n",
      " /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\u001b[0m\n",
      "\u001b[34m( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n",
      " \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n",
      "  '  |____| .__|_| |_|_| |_\\__, | / / / /\n",
      " =========|_|==============|___/=/_/_/_/\n",
      " :: Spring Boot ::                  (v2.2)\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:28.636  INFO 7 --- [           main] com.amazonaws.sagemaker.App              : Starting App v2.2 on b95ecebd125b with PID 7 (/usr/local/lib/sparkml-serving-2.2.jar started by root in /sagemaker-sparkml-model-server)\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:28.642  INFO 7 --- [           main] com.amazonaws.sagemaker.App              : No active profile set, falling back to default profiles: default\u001b[0m\n",
      "\u001b[35m  .   ____          _            __ _ _\n",
      " /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\u001b[0m\n",
      "\u001b[35m( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n",
      " \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n",
      "  '  |____| .__|_| |_|_| |_\\__, | / / / /\n",
      " =========|_|==============|___/=/_/_/_/\n",
      " :: Spring Boot ::                  (v2.2)\n",
      "\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:28.636  INFO 7 --- [           main] com.amazonaws.sagemaker.App              : Starting App v2.2 on b95ecebd125b with PID 7 (/usr/local/lib/sparkml-serving-2.2.jar started by root in /sagemaker-sparkml-model-server)\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:28.642  INFO 7 --- [           main] com.amazonaws.sagemaker.App              : No active profile set, falling back to default profiles: default\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.130  INFO 7 --- [           main] org.eclipse.jetty.util.log               : Logging initialized @3464ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.328  INFO 7 --- [           main] o.s.b.w.e.j.JettyServletWebServerFactory : Server initialized with port: 8080\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.342  INFO 7 --- [           main] org.eclipse.jetty.server.Server          : jetty-9.4.z-SNAPSHOT; built: 2018-08-30T13:59:14.071Z; git: 27208684755d94a92186989f695db2d7b21ebc51; jvm 1.8.0_181-8u181-b13-2~deb9u1-b13\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.665  INFO 7 --- [           main] org.eclipse.jetty.server.session         : DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.674  INFO 7 --- [           main] org.eclipse.jetty.server.session         : No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.130  INFO 7 --- [           main] org.eclipse.jetty.util.log               : Logging initialized @3464ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.328  INFO 7 --- [           main] o.s.b.w.e.j.JettyServletWebServerFactory : Server initialized with port: 8080\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.342  INFO 7 --- [           main] org.eclipse.jetty.server.Server          : jetty-9.4.z-SNAPSHOT; built: 2018-08-30T13:59:14.071Z; git: 27208684755d94a92186989f695db2d7b21ebc51; jvm 1.8.0_181-8u181-b13-2~deb9u1-b13\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.665  INFO 7 --- [           main] org.eclipse.jetty.server.session         : DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.674  INFO 7 --- [           main] org.eclipse.jetty.server.session         : No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.676  INFO 7 --- [           main] org.eclipse.jetty.server.session         : node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.696  INFO 7 --- [           main] o.e.j.s.h.ContextHandler.application     : Initializing Spring embedded WebApplicationContext\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.697  INFO 7 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2928 ms\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.780  INFO 7 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Servlet dispatcherServlet mapped to [/]\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.787  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.788  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.793  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'formContentFilter' to: [/*]\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.794  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.802  INFO 7 --- [           main] o.e.jetty.server.handler.ContextHandler  : Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@3a4b0e5d{application,/,[file:///tmp/jetty-docbase.5592197896846214710.8080/],AVAILABLE}\u001b[0m\n",
      "\u001b[34m2020-08-19 15:15:31.806  INFO 7 --- [           main] org.eclipse.jetty.server.Server          : Started @4142ms\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.676  INFO 7 --- [           main] org.eclipse.jetty.server.session         : node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.696  INFO 7 --- [           main] o.e.j.s.h.ContextHandler.application     : Initializing Spring embedded WebApplicationContext\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.697  INFO 7 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2928 ms\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.780  INFO 7 --- [           main] o.s.b.w.servlet.ServletRegistrationBean  : Servlet dispatcherServlet mapped to [/]\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.787  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.788  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.793  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'formContentFilter' to: [/*]\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.794  INFO 7 --- [           main] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.802  INFO 7 --- [           main] o.e.jetty.server.handler.ContextHandler  : Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@3a4b0e5d{application,/,[file:///tmp/jetty-docbase.5592197896846214710.8080/],AVAILABLE}\u001b[0m\n",
      "\u001b[35m2020-08-19 15:15:31.806  INFO 7 --- [           main] org.eclipse.jetty.server.Server          : Started @4142ms\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [13] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[32m[2020-08-19 15:15:28 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[15:15:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[15:15:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2020-08-19T15:15:34.668:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=5, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[15:15:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:34:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:34 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[15:15:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 19 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2020-08-19:15:15:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [19/Aug/2020:15:15:35 +0000] \"POST /invocations HTTP/1.1\" 200 18 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_data_path = 's3://{}/{}/{}'.format(bucket, 'batch', 'batch_input_abalone.csv')\n",
    "output_data_path = 's3://{}/{}/{}'.format(bucket, 'batch_output/abalone', timestamp_prefix)\n",
    "job_name = 'serial-inference-batch-' + timestamp_prefix\n",
    "transformer = sagemaker.transformer.Transformer(\n",
    "    # This was the model created using PipelineModel and it contains feature processing and XGBoost\n",
    "    model_name = model_name,\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    strategy = 'SingleRecord',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='serial-inference-batch',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    accept = CONTENT_TYPE_CSV\n",
    ")\n",
    "transformer.transform(data = input_data_path,\n",
    "                      job_name = job_name,\n",
    "                      content_type = CONTENT_TYPE_CSV, \n",
    "                      split_type = 'Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/batch_output/abalone/automated-job'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.222951889038086\r\n",
      "7.495278835296631\r\n",
      "10.074289321899414\r\n",
      "8.880287170410156\r\n",
      "5.981818675994873\r\n",
      "7.115278244018555\r\n",
      "13.197749137878418\r\n",
      "11.355527877807617\r\n",
      "9.285648345947266\r\n",
      "11.386305809020996\r\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "KEY = 'batch_output/abalone/automated-job/batch_input_abalone.csv.out'\n",
    "s3.Bucket(bucket).download_file(KEY, 'batch_output_abalone.csv')\n",
    "\n",
    "!head batch_output_abalone.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
